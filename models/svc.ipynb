{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%reload_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%reload_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"import warnings\\n\\nimport pandas as pd\\nimport numpy as np\\n\\nimport statsmodels.api as sm\\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\\n\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n\\nfrom sklearn.model_selection import train_test_split, GridSearchCV\\nfrom sklearn.metrics import (\\n    classification_report,\\n    confusion_matrix,\\n    fbeta_score,\\n    f1_score,\\n    make_scorer,\\n)\\n\\nfrom sklearn.pipeline import Pipeline\\nfrom sklearn.compose import ColumnTransformer\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.svm import SVC\\nfrom sklearn.decomposition import PCA\\n\\n\\n%matplotlib inline\";\n",
       "                var nbb_formatted_code = \"import warnings\\n\\nimport pandas as pd\\nimport numpy as np\\n\\nimport statsmodels.api as sm\\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\\n\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n\\nfrom sklearn.model_selection import train_test_split, GridSearchCV\\nfrom sklearn.metrics import (\\n    classification_report,\\n    confusion_matrix,\\n    fbeta_score,\\n    f1_score,\\n    make_scorer,\\n)\\n\\nfrom sklearn.pipeline import Pipeline\\nfrom sklearn.compose import ColumnTransformer\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.svm import SVC\\nfrom sklearn.decomposition import PCA\\n\\n\\n%matplotlib inline\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    fbeta_score,\n",
    "    f1_score,\n",
    "    make_scorer,\n",
    ")\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"def print_vif(x):\\n    \\\"\\\"\\\"Utility for checking multicollinearity assumption\\n    \\n    :param x: input features to check using VIF. This is assumed to be a pandas.DataFrame\\n    :return: nothing is returned the VIFs are printed as a pandas series\\n    \\\"\\\"\\\"\\n    # Silence numpy FutureWarning about .ptp\\n    with warnings.catch_warnings():\\n        warnings.simplefilter(\\\"ignore\\\")\\n        x = sm.add_constant(x)\\n\\n    vifs = []\\n    for i in range(x.shape[1]):\\n        vif = variance_inflation_factor(x.values, i)\\n        vifs.append(vif)\\n\\n    print(\\\"VIF results\\\\n-------------------------------\\\")\\n    print(pd.Series(vifs, index=x.columns))\\n    print(\\\"-------------------------------\\\\n\\\")\";\n",
       "                var nbb_formatted_code = \"def print_vif(x):\\n    \\\"\\\"\\\"Utility for checking multicollinearity assumption\\n    \\n    :param x: input features to check using VIF. This is assumed to be a pandas.DataFrame\\n    :return: nothing is returned the VIFs are printed as a pandas series\\n    \\\"\\\"\\\"\\n    # Silence numpy FutureWarning about .ptp\\n    with warnings.catch_warnings():\\n        warnings.simplefilter(\\\"ignore\\\")\\n        x = sm.add_constant(x)\\n\\n    vifs = []\\n    for i in range(x.shape[1]):\\n        vif = variance_inflation_factor(x.values, i)\\n        vifs.append(vif)\\n\\n    print(\\\"VIF results\\\\n-------------------------------\\\")\\n    print(pd.Series(vifs, index=x.columns))\\n    print(\\\"-------------------------------\\\\n\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def print_vif(x):\n",
    "    \"\"\"Utility for checking multicollinearity assumption\n",
    "    \n",
    "    :param x: input features to check using VIF. This is assumed to be a pandas.DataFrame\n",
    "    :return: nothing is returned the VIFs are printed as a pandas series\n",
    "    \"\"\"\n",
    "    # Silence numpy FutureWarning about .ptp\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        x = sm.add_constant(x)\n",
    "\n",
    "    vifs = []\n",
    "    for i in range(x.shape[1]):\n",
    "        vif = variance_inflation_factor(x.values, i)\n",
    "        vifs.append(vif)\n",
    "\n",
    "    print(\"VIF results\\n-------------------------------\")\n",
    "    print(pd.Series(vifs, index=x.columns))\n",
    "    print(\"-------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"feat_30_loc = \\\"../data/features_30_sec.csv\\\"\\nfeat_3_loc = \\\"../data/features_3_sec.csv\\\"\";\n",
       "                var nbb_formatted_code = \"feat_30_loc = \\\"../data/features_30_sec.csv\\\"\\nfeat_3_loc = \\\"../data/features_3_sec.csv\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feat_30_loc = \"../data/features_30_sec.csv\"\n",
    "feat_3_loc = \"../data/features_3_sec.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"# named long and short to differentiate easier\\nlong = pd.read_csv(feat_30_loc)\\nshort = pd.read_csv(feat_3_loc)\";\n",
       "                var nbb_formatted_code = \"# named long and short to differentiate easier\\nlong = pd.read_csv(feat_30_loc)\\nshort = pd.read_csv(feat_3_loc)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# named long and short to differentiate easier\n",
    "long = pd.read_csv(feat_30_loc)\n",
    "short = pd.read_csv(feat_3_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"# log transform the mfcc variance\\nvar_cols = short.columns[short.columns.str.contains(\\\"_var\\\")]\\nlogged_var_df = short.copy()\\nfor col in var_cols:\\n    logged_var_df[col + \\\"_logged\\\"] = np.log(logged_var_df[col])\\n    logged_var_df = logged_var_df.drop(col, 1)\";\n",
       "                var nbb_formatted_code = \"# log transform the mfcc variance\\nvar_cols = short.columns[short.columns.str.contains(\\\"_var\\\")]\\nlogged_var_df = short.copy()\\nfor col in var_cols:\\n    logged_var_df[col + \\\"_logged\\\"] = np.log(logged_var_df[col])\\n    logged_var_df = logged_var_df.drop(col, 1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# log transform the mfcc variance\n",
    "var_cols = short.columns[short.columns.str.contains(\"_var\")]\n",
    "logged_var_df = short.copy()\n",
    "for col in var_cols:\n",
    "    logged_var_df[col + \"_logged\"] = np.log(logged_var_df[col])\n",
    "    logged_var_df = logged_var_df.drop(col, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"m_start = 10  # highest mfcc to use. higher than this is too high in the frequency spectrum to really matter\\nmel_freq_drops = [f\\\"mfcc{x}_mean\\\" for x in range(m_start, 21)] + [\\n    f\\\"mfcc{x}_var_logged\\\" for x in range(m_start, 21)\\n]\";\n",
       "                var nbb_formatted_code = \"m_start = 10  # highest mfcc to use. higher than this is too high in the frequency spectrum to really matter\\nmel_freq_drops = [f\\\"mfcc{x}_mean\\\" for x in range(m_start, 21)] + [\\n    f\\\"mfcc{x}_var_logged\\\" for x in range(m_start, 21)\\n]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m_start = 10  # highest mfcc to use. higher than this is too high in the frequency spectrum to really matter\n",
    "mel_freq_drops = [f\"mfcc{x}_mean\" for x in range(m_start, 21)] + [\n",
    "    f\"mfcc{x}_var_logged\" for x in range(m_start, 21)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIF results\n",
      "-------------------------------\n",
      "const                            826.190269\n",
      "zero_crossing_rate_mean            5.025561\n",
      "mfcc2_mean                         5.399041\n",
      "mfcc3_mean                         2.220546\n",
      "mfcc4_mean                         1.978505\n",
      "mfcc5_mean                         2.504531\n",
      "mfcc6_mean                         3.073838\n",
      "mfcc7_mean                         2.834979\n",
      "mfcc8_mean                         3.033714\n",
      "mfcc9_mean                         2.325726\n",
      "rms_var_logged                     5.503822\n",
      "zero_crossing_rate_var_logged      4.491712\n",
      "perceptr_var_logged                5.541972\n",
      "mfcc1_var_logged                   3.008138\n",
      "mfcc2_var_logged                   2.786420\n",
      "mfcc3_var_logged                   2.562920\n",
      "mfcc4_var_logged                   2.858780\n",
      "mfcc5_var_logged                   2.869145\n",
      "mfcc6_var_logged                   2.976339\n",
      "mfcc7_var_logged                   2.761200\n",
      "mfcc8_var_logged                   2.455166\n",
      "mfcc9_var_logged                   2.140185\n",
      "dtype: float64\n",
      "-------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"# best balance for VIF I could tune\\ndrop_cols = [\\n    \\\"length\\\",\\n    \\\"filename\\\",\\n    \\\"label\\\",\\n    #     \\\"zero_crossing_rate_mean\\\",  # and this\\n    #     \\\"zero_crossing_rate_var_logged\\\",  # so does this\\n    \\\"rolloff_mean\\\",  # and this\\n    \\\"harmony_var_logged\\\",  # and this\\n    \\\"rolloff_var_logged\\\",\\n    \\\"spectral_centroid_var_logged\\\",\\n    \\\"spectral_bandwidth_var_logged\\\",\\n    \\\"spectral_centroid_mean\\\",\\n    \\\"spectral_bandwidth_mean\\\",\\n    \\\"rms_mean\\\",\\n    #     \\\"rms_var_logged\\\",\\n        \\\"mfcc1_mean\\\",\\n    #         \\\"mfcc2_mean\\\",\\n    #     \\\"perceptr_var_logged\\\",\\n    \\\"chroma_stft_mean\\\",\\n    \\\"chroma_stft_var_logged\\\",\\n    \\\"harmony_mean\\\",  # This causes high training guessing\\n    \\\"perceptr_mean\\\",  # this one\\n    \\\"tempo\\\",\\n]\\ndrop_cols = drop_cols + mel_freq_drops\\nprint_vif(logged_var_df.drop(drop_cols, 1,))\";\n",
       "                var nbb_formatted_code = \"# best balance for VIF I could tune\\ndrop_cols = [\\n    \\\"length\\\",\\n    \\\"filename\\\",\\n    \\\"label\\\",\\n    #     \\\"zero_crossing_rate_mean\\\",  # and this\\n    #     \\\"zero_crossing_rate_var_logged\\\",  # so does this\\n    \\\"rolloff_mean\\\",  # and this\\n    \\\"harmony_var_logged\\\",  # and this\\n    \\\"rolloff_var_logged\\\",\\n    \\\"spectral_centroid_var_logged\\\",\\n    \\\"spectral_bandwidth_var_logged\\\",\\n    \\\"spectral_centroid_mean\\\",\\n    \\\"spectral_bandwidth_mean\\\",\\n    \\\"rms_mean\\\",\\n    #     \\\"rms_var_logged\\\",\\n    \\\"mfcc1_mean\\\",\\n    #         \\\"mfcc2_mean\\\",\\n    #     \\\"perceptr_var_logged\\\",\\n    \\\"chroma_stft_mean\\\",\\n    \\\"chroma_stft_var_logged\\\",\\n    \\\"harmony_mean\\\",  # This causes high training guessing\\n    \\\"perceptr_mean\\\",  # this one\\n    \\\"tempo\\\",\\n]\\ndrop_cols = drop_cols + mel_freq_drops\\nprint_vif(logged_var_df.drop(drop_cols, 1,))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# best balance for VIF I could tune\n",
    "drop_cols = [\n",
    "    \"length\",\n",
    "    \"filename\",\n",
    "    \"label\",\n",
    "    #     \"zero_crossing_rate_mean\",  # and this\n",
    "    #     \"zero_crossing_rate_var_logged\",  # so does this\n",
    "    \"rolloff_mean\",  # and this\n",
    "    \"harmony_var_logged\",  # and this\n",
    "    \"rolloff_var_logged\",\n",
    "    \"spectral_centroid_var_logged\",\n",
    "    \"spectral_bandwidth_var_logged\",\n",
    "    \"spectral_centroid_mean\",\n",
    "    \"spectral_bandwidth_mean\",\n",
    "    \"rms_mean\",\n",
    "    #     \"rms_var_logged\",\n",
    "    \"mfcc1_mean\",\n",
    "    #         \"mfcc2_mean\",\n",
    "    #     \"perceptr_var_logged\",\n",
    "    \"chroma_stft_mean\",\n",
    "    \"chroma_stft_var_logged\",\n",
    "    \"harmony_mean\",  # This causes high training guessing\n",
    "    \"perceptr_mean\",  # this one\n",
    "    \"tempo\",\n",
    "]\n",
    "drop_cols = drop_cols + mel_freq_drops\n",
    "print_vif(logged_var_df.drop(drop_cols, 1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"drop_cols = [\\\"filename\\\", \\\"length\\\", \\\"label\\\"]\\ndrop_cols = drop_cols + mel_freq_drops\\nX = logged_var_df.drop(drop_cols, 1)\\ny = logged_var_df[\\\"label\\\"]\\n\\nX_train, X_test, y_train, y_test = train_test_split(\\n    X, y, test_size=0.2, random_state=34, stratify=y\\n)\";\n",
       "                var nbb_formatted_code = \"drop_cols = [\\\"filename\\\", \\\"length\\\", \\\"label\\\"]\\ndrop_cols = drop_cols + mel_freq_drops\\nX = logged_var_df.drop(drop_cols, 1)\\ny = logged_var_df[\\\"label\\\"]\\n\\nX_train, X_test, y_train, y_test = train_test_split(\\n    X, y, test_size=0.2, random_state=34, stratify=y\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "drop_cols = [\"filename\", \"length\", \"label\"]\n",
    "drop_cols = drop_cols + mel_freq_drops\n",
    "X = logged_var_df.drop(drop_cols, 1)\n",
    "y = logged_var_df[\"label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=34, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   8 | elapsed:   34.6s remaining:   11.5s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:   39.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7611361361361362\n",
      "0.7167167167167167\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"num_cols = list(X.columns)\\n\\nbin_cols = []\\n\\ncat_cols = []\\ndrop_cats = []\\n\\n\\npreprocessing = ColumnTransformer(\\n    [\\n        # Scale numeric columns (not needed for all models but can't hurt)\\n        (\\\"scaler\\\", StandardScaler(), num_cols)\\n    ],\\n    remainder=\\\"passthrough\\\",\\n)\\n\\n\\npipeline = Pipeline(\\n    [\\n        (\\\"preprocessing\\\", preprocessing),\\n        #         (\\\"pca\\\", PCA(n_components=10)),\\n        # Choose your model and put it here\\n        (\\\"svc\\\", SVC()),\\n    ]\\n)\\n\\n\\ngrid = {\\n    # Use model__ with hyperprammeter names after\\n    \\\"svc__C\\\": [10, 100],\\n    \\\"svc__kernel\\\": [\\\"linear\\\"],\\n    \\\"svc__decision_function_shape\\\": [\\\"ovo\\\", \\\"ovr\\\"],\\n    #     \\\"svc__degree\\\": [2, 3, 5],\\n}\\n\\n\\npipeline_cv = GridSearchCV(pipeline, grid, verbose=1, n_jobs=-1, cv=2)\\npipeline_cv.fit(X_train, y_train)\\n\\n\\nprint(pipeline_cv.score(X_train, y_train))\\nprint(pipeline_cv.score(X_test, y_test))\";\n",
       "                var nbb_formatted_code = \"num_cols = list(X.columns)\\n\\nbin_cols = []\\n\\ncat_cols = []\\ndrop_cats = []\\n\\n\\npreprocessing = ColumnTransformer(\\n    [\\n        # Scale numeric columns (not needed for all models but can't hurt)\\n        (\\\"scaler\\\", StandardScaler(), num_cols)\\n    ],\\n    remainder=\\\"passthrough\\\",\\n)\\n\\n\\npipeline = Pipeline(\\n    [\\n        (\\\"preprocessing\\\", preprocessing),\\n        #         (\\\"pca\\\", PCA(n_components=10)),\\n        # Choose your model and put it here\\n        (\\\"svc\\\", SVC()),\\n    ]\\n)\\n\\n\\ngrid = {\\n    # Use model__ with hyperprammeter names after\\n    \\\"svc__C\\\": [10, 100],\\n    \\\"svc__kernel\\\": [\\\"linear\\\"],\\n    \\\"svc__decision_function_shape\\\": [\\\"ovo\\\", \\\"ovr\\\"],\\n    #     \\\"svc__degree\\\": [2, 3, 5],\\n}\\n\\n\\npipeline_cv = GridSearchCV(pipeline, grid, verbose=1, n_jobs=-1, cv=2)\\npipeline_cv.fit(X_train, y_train)\\n\\n\\nprint(pipeline_cv.score(X_train, y_train))\\nprint(pipeline_cv.score(X_test, y_test))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_cols = list(X.columns)\n",
    "\n",
    "bin_cols = []\n",
    "\n",
    "cat_cols = []\n",
    "drop_cats = []\n",
    "\n",
    "\n",
    "preprocessing = ColumnTransformer(\n",
    "    [\n",
    "        # Scale numeric columns (not needed for all models but can't hurt)\n",
    "        (\"scaler\", StandardScaler(), num_cols)\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    ")\n",
    "\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"preprocessing\", preprocessing),\n",
    "        #         (\"pca\", PCA(n_components=10)),\n",
    "        # Choose your model and put it here\n",
    "        (\"svc\", SVC()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "grid = {\n",
    "    # Use model__ with hyperprammeter names after\n",
    "    \"svc__C\": [10, 100],\n",
    "    \"svc__kernel\": [\"linear\"],\n",
    "    \"svc__decision_function_shape\": [\"ovo\", \"ovr\"],\n",
    "    #     \"svc__degree\": [2, 3, 5],\n",
    "}\n",
    "\n",
    "\n",
    "pipeline_cv = GridSearchCV(pipeline, grid, verbose=1, n_jobs=-1, cv=2)\n",
    "pipeline_cv.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(pipeline_cv.score(X_train, y_train))\n",
    "print(pipeline_cv.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'svc__C': 100, 'svc__decision_function_shape': 'ovo', 'svc__kernel': 'linear'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"pipeline_cv.best_params_\";\n",
       "                var nbb_formatted_code = \"pipeline_cv.best_params_\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[173   0   9   3   1   5   2   0   3   4]\n",
      " [  0 189   0   0   0   9   0   1   1   0]\n",
      " [ 20   1 148   3   0   8   1   4   6   8]\n",
      " [  2   0   6 165   4   1   0   1   9  12]\n",
      " [  2   1   1   9 173   0   2   5   4   3]\n",
      " [  6   8   7   0   0 173   0   3   0   3]\n",
      " [  2   0   4   1   8   4 172   0   2   7]\n",
      " [  0   0  11   5   5   6   1 171   1   0]\n",
      " [  9   0   8   8   6   2   2   5 158   2]\n",
      " [ 13   1  20   9   4   3   8   3  12 126]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       blues       0.76      0.86      0.81       200\n",
      "   classical       0.94      0.94      0.94       200\n",
      "     country       0.69      0.74      0.72       199\n",
      "       disco       0.81      0.82      0.82       200\n",
      "      hiphop       0.86      0.86      0.86       200\n",
      "        jazz       0.82      0.86      0.84       200\n",
      "       metal       0.91      0.86      0.89       200\n",
      "         pop       0.89      0.85      0.87       200\n",
      "      reggae       0.81      0.79      0.80       200\n",
      "        rock       0.76      0.63      0.69       199\n",
      "\n",
      "    accuracy                           0.82      1998\n",
      "   macro avg       0.83      0.82      0.82      1998\n",
      "weighted avg       0.83      0.82      0.82      1998\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"y_pred = pipeline_cv.predict(X_test)\\n\\nprint(confusion_matrix(y_test, y_pred))\\nprint(classification_report(y_test, y_pred))\";\n",
       "                var nbb_formatted_code = \"y_pred = pipeline_cv.predict(X_test)\\n\\nprint(confusion_matrix(y_test, y_pred))\\nprint(classification_report(y_test, y_pred))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = pipeline_cv.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
