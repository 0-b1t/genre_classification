{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%reload_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%reload_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"import warnings\\n\\nimport pandas as pd\\nimport numpy as np\\n\\nimport statsmodels.api as sm\\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\\n\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n\\nfrom sklearn.model_selection import train_test_split, GridSearchCV\\nfrom sklearn.metrics import (\\n    classification_report,\\n    confusion_matrix,\\n    fbeta_score,\\n    f1_score,\\n    make_scorer,\\n)\\n\\nfrom sklearn.pipeline import Pipeline\\nfrom sklearn.compose import ColumnTransformer\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.decomposition import PCA\\n\\nfrom sklearn.neighbors import KNeighborsClassifier\\n\\n\\n%matplotlib inline\";\n",
       "                var nbb_formatted_code = \"import warnings\\n\\nimport pandas as pd\\nimport numpy as np\\n\\nimport statsmodels.api as sm\\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\\n\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n\\nfrom sklearn.model_selection import train_test_split, GridSearchCV\\nfrom sklearn.metrics import (\\n    classification_report,\\n    confusion_matrix,\\n    fbeta_score,\\n    f1_score,\\n    make_scorer,\\n)\\n\\nfrom sklearn.pipeline import Pipeline\\nfrom sklearn.compose import ColumnTransformer\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.decomposition import PCA\\n\\nfrom sklearn.neighbors import KNeighborsClassifier\\n\\n\\n%matplotlib inline\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    fbeta_score,\n",
    "    f1_score,\n",
    "    make_scorer,\n",
    ")\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"def print_vif(x):\\n    \\\"\\\"\\\"Utility for checking multicollinearity assumption\\n    \\n    :param x: input features to check using VIF. This is assumed to be a pandas.DataFrame\\n    :return: nothing is returned the VIFs are printed as a pandas series\\n    \\\"\\\"\\\"\\n    # Silence numpy FutureWarning about .ptp\\n    with warnings.catch_warnings():\\n        warnings.simplefilter(\\\"ignore\\\")\\n        x = sm.add_constant(x)\\n\\n    vifs = []\\n    for i in range(x.shape[1]):\\n        vif = variance_inflation_factor(x.values, i)\\n        vifs.append(vif)\\n\\n    print(\\\"VIF results\\\\n-------------------------------\\\")\\n    print(pd.Series(vifs, index=x.columns))\\n    print(\\\"-------------------------------\\\\n\\\")\";\n",
       "                var nbb_formatted_code = \"def print_vif(x):\\n    \\\"\\\"\\\"Utility for checking multicollinearity assumption\\n    \\n    :param x: input features to check using VIF. This is assumed to be a pandas.DataFrame\\n    :return: nothing is returned the VIFs are printed as a pandas series\\n    \\\"\\\"\\\"\\n    # Silence numpy FutureWarning about .ptp\\n    with warnings.catch_warnings():\\n        warnings.simplefilter(\\\"ignore\\\")\\n        x = sm.add_constant(x)\\n\\n    vifs = []\\n    for i in range(x.shape[1]):\\n        vif = variance_inflation_factor(x.values, i)\\n        vifs.append(vif)\\n\\n    print(\\\"VIF results\\\\n-------------------------------\\\")\\n    print(pd.Series(vifs, index=x.columns))\\n    print(\\\"-------------------------------\\\\n\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def print_vif(x):\n",
    "    \"\"\"Utility for checking multicollinearity assumption\n",
    "    \n",
    "    :param x: input features to check using VIF. This is assumed to be a pandas.DataFrame\n",
    "    :return: nothing is returned the VIFs are printed as a pandas series\n",
    "    \"\"\"\n",
    "    # Silence numpy FutureWarning about .ptp\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        x = sm.add_constant(x)\n",
    "\n",
    "    vifs = []\n",
    "    for i in range(x.shape[1]):\n",
    "        vif = variance_inflation_factor(x.values, i)\n",
    "        vifs.append(vif)\n",
    "\n",
    "    print(\"VIF results\\n-------------------------------\")\n",
    "    print(pd.Series(vifs, index=x.columns))\n",
    "    print(\"-------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"feat_30_loc = \\\"../data/features_30_sec.csv\\\"\\nfeat_3_loc = \\\"../data/features_3_sec.csv\\\"\\n# named long and short to differentiate easier\\nlong = pd.read_csv(feat_30_loc)\\nshort = pd.read_csv(feat_3_loc)\";\n",
       "                var nbb_formatted_code = \"feat_30_loc = \\\"../data/features_30_sec.csv\\\"\\nfeat_3_loc = \\\"../data/features_3_sec.csv\\\"\\n# named long and short to differentiate easier\\nlong = pd.read_csv(feat_30_loc)\\nshort = pd.read_csv(feat_3_loc)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feat_30_loc = \"../data/features_30_sec.csv\"\n",
    "feat_3_loc = \"../data/features_3_sec.csv\"\n",
    "# named long and short to differentiate easier\n",
    "long = pd.read_csv(feat_30_loc)\n",
    "short = pd.read_csv(feat_3_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"# log transform variances\\nvar_cols = short.columns[short.columns.str.contains(\\\"_var\\\")]\\nlogged_var_df = short.copy()\\nfor col in var_cols:\\n    logged_var_df[col + \\\"_logged\\\"] = np.log(logged_var_df[col])\\n    logged_var_df = logged_var_df.drop(col, 1)\";\n",
       "                var nbb_formatted_code = \"# log transform variances\\nvar_cols = short.columns[short.columns.str.contains(\\\"_var\\\")]\\nlogged_var_df = short.copy()\\nfor col in var_cols:\\n    logged_var_df[col + \\\"_logged\\\"] = np.log(logged_var_df[col])\\n    logged_var_df = logged_var_df.drop(col, 1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# log transform variances\n",
    "var_cols = short.columns[short.columns.str.contains(\"_var\")]\n",
    "logged_var_df = short.copy()\n",
    "for col in var_cols:\n",
    "    logged_var_df[col + \"_logged\"] = np.log(logged_var_df[col])\n",
    "    logged_var_df = logged_var_df.drop(col, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"m_start = 1  # highest mfcc to use. higher than this is too high in the frequency spectrum to really matter\\nmel_freq_drops = [f\\\"mfcc{x}_mean\\\" for x in range(m_start, 21)] + [\\n    f\\\"mfcc{x}_var_logged\\\" for x in range(m_start, 21)\\n]\";\n",
       "                var nbb_formatted_code = \"m_start = 1  # highest mfcc to use. higher than this is too high in the frequency spectrum to really matter\\nmel_freq_drops = [f\\\"mfcc{x}_mean\\\" for x in range(m_start, 21)] + [\\n    f\\\"mfcc{x}_var_logged\\\" for x in range(m_start, 21)\\n]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m_start = 1  # highest mfcc to use. higher than this is too high in the frequency spectrum to really matter\n",
    "mel_freq_drops = [f\"mfcc{x}_mean\" for x in range(m_start, 21)] + [\n",
    "    f\"mfcc{x}_var_logged\" for x in range(m_start, 21)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIF results\n",
      "-------------------------------\n",
      "const                      6.049541\n",
      "zero_crossing_rate_mean    1.000000\n",
      "dtype: float64\n",
      "-------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"# best balance for VIF I could tune\\ndrop_cols = [\\n    \\\"length\\\",\\n    \\\"filename\\\",\\n    \\\"label\\\",\\n    #     \\\"zero_crossing_rate_mean\\\",  # and this\\n    \\\"zero_crossing_rate_var_logged\\\",  # so does this\\n    \\\"rolloff_mean\\\",  # and this\\n    \\\"harmony_var_logged\\\",  # and this\\n    \\\"rolloff_var_logged\\\",\\n    \\\"spectral_centroid_var_logged\\\",\\n    \\\"spectral_bandwidth_var_logged\\\",\\n    \\\"spectral_centroid_mean\\\",\\n    \\\"spectral_bandwidth_mean\\\",\\n    \\\"rms_mean\\\",\\n    \\\"rms_var_logged\\\",\\n    #     \\\"mfcc1_mean\\\",\\n    #         \\\"mfcc2_mean\\\",\\n    \\\"perceptr_var_logged\\\",\\n    \\\"chroma_stft_mean\\\",\\n    \\\"chroma_stft_var_logged\\\",\\n    \\\"harmony_mean\\\",  # This causes high training guessing\\n    \\\"perceptr_mean\\\",  # this one\\n    \\\"tempo\\\",\\n]\\ndrop_cols = drop_cols + mel_freq_drops\\nprint_vif(logged_var_df.drop(drop_cols, 1,))\";\n",
       "                var nbb_formatted_code = \"# best balance for VIF I could tune\\ndrop_cols = [\\n    \\\"length\\\",\\n    \\\"filename\\\",\\n    \\\"label\\\",\\n    #     \\\"zero_crossing_rate_mean\\\",  # and this\\n    \\\"zero_crossing_rate_var_logged\\\",  # so does this\\n    \\\"rolloff_mean\\\",  # and this\\n    \\\"harmony_var_logged\\\",  # and this\\n    \\\"rolloff_var_logged\\\",\\n    \\\"spectral_centroid_var_logged\\\",\\n    \\\"spectral_bandwidth_var_logged\\\",\\n    \\\"spectral_centroid_mean\\\",\\n    \\\"spectral_bandwidth_mean\\\",\\n    \\\"rms_mean\\\",\\n    \\\"rms_var_logged\\\",\\n    #     \\\"mfcc1_mean\\\",\\n    #         \\\"mfcc2_mean\\\",\\n    \\\"perceptr_var_logged\\\",\\n    \\\"chroma_stft_mean\\\",\\n    \\\"chroma_stft_var_logged\\\",\\n    \\\"harmony_mean\\\",  # This causes high training guessing\\n    \\\"perceptr_mean\\\",  # this one\\n    \\\"tempo\\\",\\n]\\ndrop_cols = drop_cols + mel_freq_drops\\nprint_vif(logged_var_df.drop(drop_cols, 1,))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# best balance for VIF I could tune\n",
    "drop_cols = [\n",
    "    \"length\",\n",
    "    \"filename\",\n",
    "    \"label\",\n",
    "    #     \"zero_crossing_rate_mean\",  # and this\n",
    "    \"zero_crossing_rate_var_logged\",  # so does this\n",
    "    \"rolloff_mean\",  # and this\n",
    "    \"harmony_var_logged\",  # and this\n",
    "    \"rolloff_var_logged\",\n",
    "    \"spectral_centroid_var_logged\",\n",
    "    \"spectral_bandwidth_var_logged\",\n",
    "    \"spectral_centroid_mean\",\n",
    "    \"spectral_bandwidth_mean\",\n",
    "    \"rms_mean\",\n",
    "    \"rms_var_logged\",\n",
    "    #     \"mfcc1_mean\",\n",
    "    #         \"mfcc2_mean\",\n",
    "    \"perceptr_var_logged\",\n",
    "    \"chroma_stft_mean\",\n",
    "    \"chroma_stft_var_logged\",\n",
    "    \"harmony_mean\",  # This causes high training guessing\n",
    "    \"perceptr_mean\",  # this one\n",
    "    \"tempo\",\n",
    "]\n",
    "drop_cols = drop_cols + mel_freq_drops\n",
    "print_vif(logged_var_df.drop(drop_cols, 1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"X = logged_var_df.drop(drop_cols, 1,)\\ny = logged_var_df[\\\"label\\\"]\\n\\nX_train, X_test, y_train, y_test = train_test_split(\\n    X, y, test_size=0.2, random_state=34, stratify=y\\n)\";\n",
       "                var nbb_formatted_code = \"X = logged_var_df.drop(drop_cols, 1,)\\ny = logged_var_df[\\\"label\\\"]\\n\\nX_train, X_test, y_train, y_test = train_test_split(\\n    X, y, test_size=0.2, random_state=34, stratify=y\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = logged_var_df.drop(drop_cols, 1,)\n",
    "y = logged_var_df[\"label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=34, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drop_cols = [\"filename\", \"length\", \"label\"]\n",
    "# drop_cols = drop_cols + mel_freq_drops\n",
    "X = logged_var_df.drop(drop_cols, 1)\n",
    "y = logged_var_df[\"label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=12, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "0.9993743743743744\n",
      "0.12862862862862862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'knn__algorithm': 'kd_tree',\n",
       " 'knn__leaf_size': 30,\n",
       " 'knn__n_neighbors': 5,\n",
       " 'knn__weights': 'distance'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"num_cols = list(X.columns)\\n\\nbin_cols = []\\n\\ncat_cols = []\\ndrop_cats = []\\n\\n\\npreprocessing = ColumnTransformer(\\n    [\\n        # Scale numeric columns (not needed for all models but can't hurt)\\n        (\\\"scaler\\\", StandardScaler(), num_cols)\\n    ],\\n    remainder=\\\"passthrough\\\",\\n)\\n\\n\\npipeline = Pipeline(\\n    [\\n        (\\\"preprocessing\\\", preprocessing),\\n        #         (\\\"pca\\\", PCA()),\\n        # Choose your model and put it here\\n        (\\\"knn\\\", KNeighborsClassifier()),\\n    ]\\n)\\n\\n\\nparams = {\\n    \\\"knn__n_neighbors\\\": [ 5],\\n    \\\"knn__weights\\\": [\\\"distance\\\"],\\n    \\\"knn__leaf_size\\\": [30],\\n    \\\"knn__algorithm\\\": [\\\"kd_tree\\\", \\\"ball_tree\\\"],\\n}\\n\\n\\npipeline_cv = GridSearchCV(pipeline, params, verbose=1, n_jobs=-1, cv=5)\\n\\npipeline_cv.fit(X_train, y=y_train)\\n\\n\\nprint(pipeline_cv.score(X_train, y_train))\\nprint(pipeline_cv.score(X_test, y_test))\\npipeline_cv.best_params_\";\n",
       "                var nbb_formatted_code = \"num_cols = list(X.columns)\\n\\nbin_cols = []\\n\\ncat_cols = []\\ndrop_cats = []\\n\\n\\npreprocessing = ColumnTransformer(\\n    [\\n        # Scale numeric columns (not needed for all models but can't hurt)\\n        (\\\"scaler\\\", StandardScaler(), num_cols)\\n    ],\\n    remainder=\\\"passthrough\\\",\\n)\\n\\n\\npipeline = Pipeline(\\n    [\\n        (\\\"preprocessing\\\", preprocessing),\\n        #         (\\\"pca\\\", PCA()),\\n        # Choose your model and put it here\\n        (\\\"knn\\\", KNeighborsClassifier()),\\n    ]\\n)\\n\\n\\nparams = {\\n    \\\"knn__n_neighbors\\\": [5],\\n    \\\"knn__weights\\\": [\\\"distance\\\"],\\n    \\\"knn__leaf_size\\\": [30],\\n    \\\"knn__algorithm\\\": [\\\"kd_tree\\\", \\\"ball_tree\\\"],\\n}\\n\\n\\npipeline_cv = GridSearchCV(pipeline, params, verbose=1, n_jobs=-1, cv=5)\\n\\npipeline_cv.fit(X_train, y=y_train)\\n\\n\\nprint(pipeline_cv.score(X_train, y_train))\\nprint(pipeline_cv.score(X_test, y_test))\\npipeline_cv.best_params_\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_cols = list(X.columns)\n",
    "\n",
    "bin_cols = []\n",
    "\n",
    "cat_cols = []\n",
    "drop_cats = []\n",
    "\n",
    "\n",
    "preprocessing = ColumnTransformer(\n",
    "    [\n",
    "        # Scale numeric columns (not needed for all models but can't hurt)\n",
    "        (\"scaler\", StandardScaler(), num_cols)\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    ")\n",
    "\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"preprocessing\", preprocessing),\n",
    "        #         (\"pca\", PCA()),\n",
    "        # Choose your model and put it here\n",
    "        (\"knn\", KNeighborsClassifier()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "params = {\n",
    "    \"knn__n_neighbors\": [5],\n",
    "    \"knn__weights\": [\"distance\"],\n",
    "    \"knn__leaf_size\": [30],\n",
    "    \"knn__algorithm\": [\"kd_tree\", \"ball_tree\"],\n",
    "}\n",
    "\n",
    "\n",
    "pipeline_cv = GridSearchCV(pipeline, params, verbose=1, n_jobs=-1, cv=5)\n",
    "\n",
    "pipeline_cv.fit(X_train, y=y_train)\n",
    "\n",
    "\n",
    "print(pipeline_cv.score(X_train, y_train))\n",
    "print(pipeline_cv.score(X_test, y_test))\n",
    "pipeline_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chroma_stft_mean',\n",
       " 'rms_mean',\n",
       " 'spectral_centroid_mean',\n",
       " 'spectral_bandwidth_mean',\n",
       " 'rolloff_mean',\n",
       " 'zero_crossing_rate_mean',\n",
       " 'harmony_mean',\n",
       " 'perceptr_mean',\n",
       " 'tempo',\n",
       " 'mfcc1_mean',\n",
       " 'mfcc2_mean',\n",
       " 'mfcc3_mean',\n",
       " 'mfcc4_mean',\n",
       " 'mfcc5_mean',\n",
       " 'mfcc6_mean',\n",
       " 'mfcc7_mean',\n",
       " 'mfcc8_mean',\n",
       " 'mfcc9_mean',\n",
       " 'mfcc10_mean',\n",
       " 'mfcc11_mean',\n",
       " 'mfcc12_mean',\n",
       " 'mfcc13_mean',\n",
       " 'mfcc14_mean',\n",
       " 'mfcc15_mean',\n",
       " 'mfcc16_mean',\n",
       " 'mfcc17_mean',\n",
       " 'mfcc18_mean',\n",
       " 'mfcc19_mean',\n",
       " 'mfcc20_mean',\n",
       " 'chroma_stft_var_logged',\n",
       " 'rms_var_logged',\n",
       " 'spectral_centroid_var_logged',\n",
       " 'spectral_bandwidth_var_logged',\n",
       " 'rolloff_var_logged',\n",
       " 'zero_crossing_rate_var_logged',\n",
       " 'harmony_var_logged',\n",
       " 'perceptr_var_logged',\n",
       " 'mfcc1_var_logged',\n",
       " 'mfcc2_var_logged',\n",
       " 'mfcc3_var_logged',\n",
       " 'mfcc4_var_logged',\n",
       " 'mfcc5_var_logged',\n",
       " 'mfcc6_var_logged',\n",
       " 'mfcc7_var_logged',\n",
       " 'mfcc8_var_logged',\n",
       " 'mfcc9_var_logged',\n",
       " 'mfcc10_var_logged',\n",
       " 'mfcc11_var_logged',\n",
       " 'mfcc12_var_logged',\n",
       " 'mfcc13_var_logged',\n",
       " 'mfcc14_var_logged',\n",
       " 'mfcc15_var_logged',\n",
       " 'mfcc16_var_logged',\n",
       " 'mfcc17_var_logged',\n",
       " 'mfcc18_var_logged',\n",
       " 'mfcc19_var_logged',\n",
       " 'mfcc20_var_logged']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"all_feat_cols = list(logged_var_df.columns[2:])\\nall_feat_cols.remove(\\\"label\\\")\\nall_feat_cols\";\n",
       "                var nbb_formatted_code = \"all_feat_cols = list(logged_var_df.columns[2:])\\nall_feat_cols.remove(\\\"label\\\")\\nall_feat_cols\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_feat_cols = list(logged_var_df.columns[2:])\n",
    "all_feat_cols.remove(\"label\")\n",
    "all_feat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"from sklearn.svm import SVC\\nfrom sklearn.ensemble import RandomForestClassifier\";\n",
       "                var nbb_formatted_code = \"from sklearn.svm import SVC\\nfrom sklearn.ensemble import RandomForestClassifier\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chroma_stft_mean\n",
      "0.4446946946946947\n",
      "0.20770770770770772\n",
      "rms_mean\n",
      "0.4403153153153153\n",
      "0.21171171171171171\n",
      "spectral_centroid_mean\n",
      "0.43355855855855857\n",
      "0.19519519519519518\n",
      "spectral_bandwidth_mean\n",
      "0.4555805805805806\n",
      "0.22322322322322322\n",
      "rolloff_mean\n",
      "0.4403153153153153\n",
      "0.2067067067067067\n",
      "zero_crossing_rate_mean\n",
      "0.4025275275275275\n",
      "0.16716716716716717\n",
      "harmony_mean\n",
      "0.3997747747747748\n",
      "0.17367367367367367\n",
      "perceptr_mean\n",
      "0.40503003003003\n",
      "0.15315315315315314\n",
      "tempo\n",
      "0.11211211211211211\n",
      "0.09759759759759759\n",
      "mfcc1_mean\n",
      "0.4371871871871872\n",
      "0.2047047047047047\n",
      "mfcc2_mean\n",
      "0.4271771771771772\n",
      "0.19369369369369369\n",
      "mfcc3_mean\n",
      "0.4004004004004004\n",
      "0.15165165165165165\n",
      "mfcc4_mean\n",
      "0.4152902902902903\n",
      "0.17317317317317318\n",
      "mfcc5_mean\n",
      "0.39376876876876876\n",
      "0.13813813813813813\n",
      "mfcc6_mean\n",
      "0.40965965965965967\n",
      "0.16266266266266266\n",
      "mfcc7_mean\n",
      "0.3993993993993994\n",
      "0.14864864864864866\n",
      "mfcc8_mean\n",
      "0.41178678678678676\n",
      "0.15465465465465467\n",
      "mfcc9_mean\n",
      "0.41266266266266266\n",
      "0.17367367367367367\n",
      "mfcc10_mean\n",
      "0.3978978978978979\n",
      "0.15165165165165165\n",
      "mfcc11_mean\n",
      "0.3958958958958959\n",
      "0.14764764764764765\n",
      "mfcc12_mean\n",
      "0.40202702702702703\n",
      "0.15915915915915915\n",
      "mfcc13_mean\n",
      "0.38813813813813813\n",
      "0.14214214214214213\n",
      "mfcc14_mean\n",
      "0.390015015015015\n",
      "0.11361361361361362\n",
      "mfcc15_mean\n",
      "0.3957707707707708\n",
      "0.13163163163163163\n",
      "mfcc16_mean\n",
      "0.39214214214214216\n",
      "0.12912912912912913\n",
      "mfcc17_mean\n",
      "0.39602102102102105\n",
      "0.14364364364364365\n",
      "mfcc18_mean\n",
      "0.3704954954954955\n",
      "0.1046046046046046\n",
      "mfcc19_mean\n",
      "0.3783783783783784\n",
      "0.11861861861861862\n",
      "mfcc20_mean\n",
      "0.3791291291291291\n",
      "0.12512512512512514\n",
      "chroma_stft_var_logged\n",
      "0.4116616616616617\n",
      "0.15965965965965967\n",
      "rms_var_logged\n",
      "0.44644644644644643\n",
      "0.2157157157157157\n",
      "spectral_centroid_var_logged\n",
      "0.44319319319319317\n",
      "0.2042042042042042\n",
      "spectral_bandwidth_var_logged\n",
      "0.40603103103103105\n",
      "0.17117117117117117\n",
      "rolloff_var_logged\n",
      "0.4269269269269269\n",
      "0.18118118118118118\n",
      "zero_crossing_rate_var_logged\n",
      "0.4132882882882883\n",
      "0.17317317317317318\n",
      "harmony_var_logged\n",
      "0.4323073073073073\n",
      "0.20520520520520522\n",
      "perceptr_var_logged\n",
      "0.47985485485485485\n",
      "0.24974974974974976\n",
      "mfcc1_var_logged\n",
      "0.4057807807807808\n",
      "0.16366366366366367\n",
      "mfcc2_var_logged\n",
      "0.40515515515515516\n",
      "0.14314314314314314\n",
      "mfcc3_var_logged\n",
      "0.40102602602602605\n",
      "0.15615615615615616\n",
      "mfcc4_var_logged\n",
      "0.42179679679679677\n",
      "0.17917917917917917\n",
      "mfcc5_var_logged\n",
      "0.40703203203203203\n",
      "0.17367367367367367\n",
      "mfcc6_var_logged\n",
      "0.4114114114114114\n",
      "0.15115115115115116\n",
      "mfcc7_var_logged\n",
      "0.4089089089089089\n",
      "0.15615615615615616\n",
      "mfcc8_var_logged\n",
      "0.3958958958958959\n",
      "0.15465465465465467\n",
      "mfcc9_var_logged\n",
      "0.3922672672672673\n",
      "0.11861861861861862\n",
      "mfcc10_var_logged\n",
      "0.388013013013013\n",
      "0.14814814814814814\n",
      "mfcc11_var_logged\n",
      "0.38400900900900903\n",
      "0.14064064064064064\n",
      "mfcc12_var_logged\n",
      "0.38726226226226224\n",
      "0.13463463463463463\n",
      "mfcc13_var_logged\n",
      "0.38313313313313313\n",
      "0.13613613613613615\n",
      "mfcc14_var_logged\n",
      "0.3888888888888889\n",
      "0.13513513513513514\n",
      "mfcc15_var_logged\n",
      "0.3843843843843844\n",
      "0.12012012012012012\n",
      "mfcc16_var_logged\n",
      "0.3755005005005005\n",
      "0.12912912912912913\n",
      "mfcc17_var_logged\n",
      "0.38063063063063063\n",
      "0.13013013013013014\n",
      "mfcc18_var_logged\n",
      "0.38400900900900903\n",
      "0.10810810810810811\n",
      "mfcc19_var_logged\n",
      "0.3786286286286286\n",
      "0.12162162162162163\n",
      "mfcc20_var_logged\n",
      "0.3781281281281281\n",
      "0.12962962962962962\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"for col in all_feat_cols:\\n    X = logged_var_df[[col]]\\n    y = logged_var_df[\\\"label\\\"]\\n    X_train, X_test, y_train, y_test = train_test_split(\\n        X, y, test_size=0.2, random_state=34, stratify=y\\n    )\\n    num_cols = list(X.columns)\\n\\n    bin_cols = []\\n\\n    cat_cols = []\\n    drop_cats = []\\n\\n    preprocessing = ColumnTransformer(\\n        [\\n            # Scale numeric columns (not needed for all models but can't hurt)\\n            (\\\"scaler\\\", StandardScaler(), num_cols)\\n        ],\\n        remainder=\\\"passthrough\\\",\\n    )\\n\\n    pipeline = Pipeline(\\n        [\\n            (\\\"preprocessing\\\", preprocessing),\\n            # (\\\"pca\\\", PCA()),\\n            # Choose your model and put it here\\n            (\\\"knn\\\", KNeighborsClassifier()),\\n            # (\\\"svc\\\", SVC()),\\n        ]\\n    )\\n\\n    # params = {\\n    #         \\\"knn__n_neighbors\\\": [5],\\n    #         \\\"knn__weights\\\": [\\\"distance\\\"],\\n    #         \\\"knn__leaf_size\\\": [30],\\n    #         \\\"knn__algorithm\\\": [\\\"kd_tree\\\"],\\n    #     }\\n    # pipeline_cv = GridSearchCV(pipeline, params, verbose=0, n_jobs=-1, cv=2)\\n\\n    pipeline.fit(X_train, y=y_train)\\n\\n    print(col)\\n    print(pipeline.score(X_train, y_train))\\n    print(pipeline.score(X_test, y_test))\";\n",
       "                var nbb_formatted_code = \"for col in all_feat_cols:\\n    X = logged_var_df[[col]]\\n    y = logged_var_df[\\\"label\\\"]\\n    X_train, X_test, y_train, y_test = train_test_split(\\n        X, y, test_size=0.2, random_state=34, stratify=y\\n    )\\n    num_cols = list(X.columns)\\n\\n    bin_cols = []\\n\\n    cat_cols = []\\n    drop_cats = []\\n\\n    preprocessing = ColumnTransformer(\\n        [\\n            # Scale numeric columns (not needed for all models but can't hurt)\\n            (\\\"scaler\\\", StandardScaler(), num_cols)\\n        ],\\n        remainder=\\\"passthrough\\\",\\n    )\\n\\n    pipeline = Pipeline(\\n        [\\n            (\\\"preprocessing\\\", preprocessing),\\n            # (\\\"pca\\\", PCA()),\\n            # Choose your model and put it here\\n            (\\\"knn\\\", KNeighborsClassifier()),\\n            # (\\\"svc\\\", SVC()),\\n        ]\\n    )\\n\\n    # params = {\\n    #         \\\"knn__n_neighbors\\\": [5],\\n    #         \\\"knn__weights\\\": [\\\"distance\\\"],\\n    #         \\\"knn__leaf_size\\\": [30],\\n    #         \\\"knn__algorithm\\\": [\\\"kd_tree\\\"],\\n    #     }\\n    # pipeline_cv = GridSearchCV(pipeline, params, verbose=0, n_jobs=-1, cv=2)\\n\\n    pipeline.fit(X_train, y=y_train)\\n\\n    print(col)\\n    print(pipeline.score(X_train, y_train))\\n    print(pipeline.score(X_test, y_test))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for col in all_feat_cols:\n",
    "    X = logged_var_df[[col]]\n",
    "    y = logged_var_df[\"label\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=34, stratify=y\n",
    "    )\n",
    "    num_cols = list(X.columns)\n",
    "\n",
    "    bin_cols = []\n",
    "\n",
    "    cat_cols = []\n",
    "    drop_cats = []\n",
    "\n",
    "    preprocessing = ColumnTransformer(\n",
    "        [\n",
    "            # Scale numeric columns (not needed for all models but can't hurt)\n",
    "            (\"scaler\", StandardScaler(), num_cols)\n",
    "        ],\n",
    "        remainder=\"passthrough\",\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline(\n",
    "        [\n",
    "            (\"preprocessing\", preprocessing),\n",
    "            # (\"pca\", PCA()),\n",
    "            # Choose your model and put it here\n",
    "            (\"knn\", KNeighborsClassifier()),\n",
    "            # (\"svc\", SVC()),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # params = {\n",
    "    #         \"knn__n_neighbors\": [5],\n",
    "    #         \"knn__weights\": [\"distance\"],\n",
    "    #         \"knn__leaf_size\": [30],\n",
    "    #         \"knn__algorithm\": [\"kd_tree\"],\n",
    "    #     }\n",
    "    # pipeline_cv = GridSearchCV(pipeline, params, verbose=0, n_jobs=-1, cv=2)\n",
    "\n",
    "    pipeline.fit(X_train, y=y_train)\n",
    "\n",
    "    print(col)\n",
    "    print(pipeline.score(X_train, y_train))\n",
    "    print(pipeline.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in all_feat_cols:\n",
    "    X = logged_var_df[[col]]\n",
    "    y = logged_var_df[\"label\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=34, stratify=y\n",
    "    )\n",
    "    num_cols = list(X.columns)\n",
    "\n",
    "    bin_cols = []\n",
    "\n",
    "    cat_cols = []\n",
    "    drop_cats = []\n",
    "\n",
    "    preprocessing = ColumnTransformer(\n",
    "        [\n",
    "            # Scale numeric columns (not needed for all models but can't hurt)\n",
    "            (\"scaler\", StandardScaler(), num_cols)\n",
    "        ],\n",
    "        remainder=\"passthrough\",\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline(\n",
    "        [\n",
    "            (\"preprocessing\", preprocessing),\n",
    "            #         (\"pca\", PCA()),\n",
    "            # Choose your model and put it here\n",
    "            # (\"knn\", KNeighborsClassifier()),\n",
    "            #(\"svc\", SVC()),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # params = {\n",
    "    #         \"knn__n_neighbors\": [5],\n",
    "    #         \"knn__weights\": [\"distance\"],\n",
    "    #         \"knn__leaf_size\": [30],\n",
    "    #         \"knn__algorithm\": [\"kd_tree\"],\n",
    "    #     }\n",
    "    # pipeline_cv = GridSearchCV(pipeline, params, verbose=0, n_jobs=-1, cv=2)\n",
    "\n",
    "    pipeline.fit(X_train, y=y_train)\n",
    "\n",
    "    print(col)\n",
    "    print(pipeline.score(X_train, y_train))\n",
    "    print(pipeline.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
