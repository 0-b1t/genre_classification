{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%reload_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%reload_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"import warnings\\n\\nimport pandas as pd\\nimport numpy as np\\n\\nimport statsmodels.api as sm\\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\\n\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n\\nfrom sklearn.model_selection import train_test_split, GridSearchCV\\nfrom sklearn.metrics import (\\n    classification_report,\\n    confusion_matrix,\\n    fbeta_score,\\n    f1_score,\\n    make_scorer,\\n)\\n\\nfrom sklearn.pipeline import Pipeline\\nfrom sklearn.compose import ColumnTransformer\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.decomposition import PCA\\nfrom sklearn.ensemble import RandomForestClassifier\\n\\n\\n%matplotlib inline\";\n",
       "                var nbb_formatted_code = \"import warnings\\n\\nimport pandas as pd\\nimport numpy as np\\n\\nimport statsmodels.api as sm\\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\\n\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n\\nfrom sklearn.model_selection import train_test_split, GridSearchCV\\nfrom sklearn.metrics import (\\n    classification_report,\\n    confusion_matrix,\\n    fbeta_score,\\n    f1_score,\\n    make_scorer,\\n)\\n\\nfrom sklearn.pipeline import Pipeline\\nfrom sklearn.compose import ColumnTransformer\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.decomposition import PCA\\nfrom sklearn.ensemble import RandomForestClassifier\\n\\n\\n%matplotlib inline\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    fbeta_score,\n",
    "    f1_score,\n",
    "    make_scorer,\n",
    ")\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"def print_vif(x):\\n    \\\"\\\"\\\"Utility for checking multicollinearity assumption\\n    \\n    :param x: input features to check using VIF. This is assumed to be a pandas.DataFrame\\n    :return: nothing is returned the VIFs are printed as a pandas series\\n    \\\"\\\"\\\"\\n    # Silence numpy FutureWarning about .ptp\\n    with warnings.catch_warnings():\\n        warnings.simplefilter(\\\"ignore\\\")\\n        x = sm.add_constant(x)\\n\\n    vifs = []\\n    for i in range(x.shape[1]):\\n        vif = variance_inflation_factor(x.values, i)\\n        vifs.append(vif)\\n\\n    print(\\\"VIF results\\\\n-------------------------------\\\")\\n    print(pd.Series(vifs, index=x.columns))\\n    print(\\\"-------------------------------\\\\n\\\")\";\n",
       "                var nbb_formatted_code = \"def print_vif(x):\\n    \\\"\\\"\\\"Utility for checking multicollinearity assumption\\n    \\n    :param x: input features to check using VIF. This is assumed to be a pandas.DataFrame\\n    :return: nothing is returned the VIFs are printed as a pandas series\\n    \\\"\\\"\\\"\\n    # Silence numpy FutureWarning about .ptp\\n    with warnings.catch_warnings():\\n        warnings.simplefilter(\\\"ignore\\\")\\n        x = sm.add_constant(x)\\n\\n    vifs = []\\n    for i in range(x.shape[1]):\\n        vif = variance_inflation_factor(x.values, i)\\n        vifs.append(vif)\\n\\n    print(\\\"VIF results\\\\n-------------------------------\\\")\\n    print(pd.Series(vifs, index=x.columns))\\n    print(\\\"-------------------------------\\\\n\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def print_vif(x):\n",
    "    \"\"\"Utility for checking multicollinearity assumption\n",
    "    \n",
    "    :param x: input features to check using VIF. This is assumed to be a pandas.DataFrame\n",
    "    :return: nothing is returned the VIFs are printed as a pandas series\n",
    "    \"\"\"\n",
    "    # Silence numpy FutureWarning about .ptp\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        x = sm.add_constant(x)\n",
    "\n",
    "    vifs = []\n",
    "    for i in range(x.shape[1]):\n",
    "        vif = variance_inflation_factor(x.values, i)\n",
    "        vifs.append(vif)\n",
    "\n",
    "    print(\"VIF results\\n-------------------------------\")\n",
    "    print(pd.Series(vifs, index=x.columns))\n",
    "    print(\"-------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"feat_30_loc = \\\"../data/features_30_sec.csv\\\"\\nfeat_3_loc = \\\"../data/features_3_sec.csv\\\"\";\n",
       "                var nbb_formatted_code = \"feat_30_loc = \\\"../data/features_30_sec.csv\\\"\\nfeat_3_loc = \\\"../data/features_3_sec.csv\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feat_30_loc = \"../data/features_30_sec.csv\"\n",
    "feat_3_loc = \"../data/features_3_sec.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"# named long and short to differentiate easier\\nlong = pd.read_csv(feat_30_loc)\\nshort = pd.read_csv(feat_3_loc)\";\n",
       "                var nbb_formatted_code = \"# named long and short to differentiate easier\\nlong = pd.read_csv(feat_30_loc)\\nshort = pd.read_csv(feat_3_loc)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# named long and short to differentiate easier\n",
    "long = pd.read_csv(feat_30_loc)\n",
    "short = pd.read_csv(feat_3_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"# log transform the variance cols\\nvar_cols = short.columns[short.columns.str.contains(\\\"_var\\\")]\\nlogged_var_df = short.copy()\\nfor col in var_cols:\\n    logged_var_df[col + \\\"_logged\\\"] = np.log(logged_var_df[col])\\n    logged_var_df = logged_var_df.drop(col, 1)\";\n",
       "                var nbb_formatted_code = \"# log transform the variance cols\\nvar_cols = short.columns[short.columns.str.contains(\\\"_var\\\")]\\nlogged_var_df = short.copy()\\nfor col in var_cols:\\n    logged_var_df[col + \\\"_logged\\\"] = np.log(logged_var_df[col])\\n    logged_var_df = logged_var_df.drop(col, 1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# log transform the variance cols\n",
    "var_cols = short.columns[short.columns.str.contains(\"_var\")]\n",
    "logged_var_df = short.copy()\n",
    "for col in var_cols:\n",
    "    logged_var_df[col + \"_logged\"] = np.log(logged_var_df[col])\n",
    "    logged_var_df = logged_var_df.drop(col, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"m_start = 12  # highest mfcc to use. higher than this is too high in the frequency spectrum to really matter\\nmel_freq_drops = [f\\\"mfcc{x}_mean\\\" for x in range(m_start, 21)] + [\\n    f\\\"mfcc{x}_var_logged\\\" for x in range(m_start, 21)\\n]\";\n",
       "                var nbb_formatted_code = \"m_start = 12  # highest mfcc to use. higher than this is too high in the frequency spectrum to really matter\\nmel_freq_drops = [f\\\"mfcc{x}_mean\\\" for x in range(m_start, 21)] + [\\n    f\\\"mfcc{x}_var_logged\\\" for x in range(m_start, 21)\\n]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m_start = 12  # highest mfcc to use. higher than this is too high in the frequency spectrum to really matter\n",
    "mel_freq_drops = [f\"mfcc{x}_mean\" for x in range(m_start, 21)] + [\n",
    "    f\"mfcc{x}_var_logged\" for x in range(m_start, 21)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"# # best balance for VIF I could tune\\n# drop_cols = [\\n#     \\\"length\\\",\\n#     \\\"filename\\\",\\n#     \\\"label\\\",\\n#     #     \\\"zero_crossing_rate_mean\\\",\\n#     #     \\\"zero_crossing_rate_var\\\",\\n#     \\\"rolloff_mean\\\",\\n#     \\\"harmony_var\\\",\\n#     \\\"rolloff_var\\\",\\n#     \\\"spectral_centroid_var\\\",\\n#     \\\"spectral_bandwidth_var\\\",\\n#     \\\"spectral_centroid_mean\\\",\\n#     \\\"spectral_bandwidth_mean\\\",\\n#     #     \\\"rms_mean\\\",\\n#     #     \\\"rms_var\\\",\\n# ]\\n# drop_cols = drop_cols + mel_freq_drops\\n# print_vif(logged_cc_var_df.drop(drop_cols, 1,))\";\n",
       "                var nbb_formatted_code = \"# # best balance for VIF I could tune\\n# drop_cols = [\\n#     \\\"length\\\",\\n#     \\\"filename\\\",\\n#     \\\"label\\\",\\n#     #     \\\"zero_crossing_rate_mean\\\",\\n#     #     \\\"zero_crossing_rate_var\\\",\\n#     \\\"rolloff_mean\\\",\\n#     \\\"harmony_var\\\",\\n#     \\\"rolloff_var\\\",\\n#     \\\"spectral_centroid_var\\\",\\n#     \\\"spectral_bandwidth_var\\\",\\n#     \\\"spectral_centroid_mean\\\",\\n#     \\\"spectral_bandwidth_mean\\\",\\n#     #     \\\"rms_mean\\\",\\n#     #     \\\"rms_var\\\",\\n# ]\\n# drop_cols = drop_cols + mel_freq_drops\\n# print_vif(logged_cc_var_df.drop(drop_cols, 1,))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # best balance for VIF I could tune\n",
    "# drop_cols = [\n",
    "#     \"length\",\n",
    "#     \"filename\",\n",
    "#     \"label\",\n",
    "#     #     \"zero_crossing_rate_mean\",\n",
    "#     #     \"zero_crossing_rate_var\",\n",
    "#     \"rolloff_mean\",\n",
    "#     \"harmony_var\",\n",
    "#     \"rolloff_var\",\n",
    "#     \"spectral_centroid_var\",\n",
    "#     \"spectral_bandwidth_var\",\n",
    "#     \"spectral_centroid_mean\",\n",
    "#     \"spectral_bandwidth_mean\",\n",
    "#     #     \"rms_mean\",\n",
    "#     #     \"rms_var\",\n",
    "# ]\n",
    "# drop_cols = drop_cols + mel_freq_drops\n",
    "# print_vif(logged_cc_var_df.drop(drop_cols, 1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"drop_cols = [\\\"filename\\\", \\\"length\\\", \\\"label\\\"]\\n# drop_cols = drop_cols + mel_freq_drops\\nX = logged_var_df.drop(drop_cols, 1)\\ny = logged_var_df[\\\"label\\\"]\\n\\nX_train, X_test, y_train, y_test = train_test_split(\\n    X, y, test_size=0.2, random_state=34, stratify=y\\n)\";\n",
       "                var nbb_formatted_code = \"drop_cols = [\\\"filename\\\", \\\"length\\\", \\\"label\\\"]\\n# drop_cols = drop_cols + mel_freq_drops\\nX = logged_var_df.drop(drop_cols, 1)\\ny = logged_var_df[\\\"label\\\"]\\n\\nX_train, X_test, y_train, y_test = train_test_split(\\n    X, y, test_size=0.2, random_state=34, stratify=y\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "drop_cols = [\"filename\", \"length\", \"label\"]\n",
    "# drop_cols = drop_cols + mel_freq_drops\n",
    "X = logged_var_df.drop(drop_cols, 1)\n",
    "y = logged_var_df[\"label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=34, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 18 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:   12.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8193193193193193\n",
      "0.6716716716716716\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"num_cols = list(X.columns)\\n\\nbin_cols = []\\n\\ncat_cols = []\\ndrop_cats = []\\n\\n\\npreprocessing = ColumnTransformer(\\n    [\\n        # Scale numeric columns (not needed for all models but can't hurt)\\n        (\\\"scaler\\\", StandardScaler(), num_cols)\\n    ],\\n    remainder=\\\"passthrough\\\",\\n)\\n\\n\\npipeline = Pipeline(\\n    [\\n        (\\\"preprocessing\\\", preprocessing),\\n        (\\\"pca\\\", PCA(n_components=8)),\\n        # Choose your model and put it here\\n        (\\\"rfc\\\", RandomForestClassifier()),\\n    ]\\n)\\n\\n\\ngrid = {\\n    # Use model__ with hyperprammeter names after\\n    \\\"rfc__criterion\\\": [\\\"gini\\\", \\\"entropy\\\"],\\n    \\\"rfc__max_depth\\\": [10, 14, 20],\\n    \\\"rfc__min_samples_leaf\\\": [10, 16, 20],\\n}\\n\\nn_trees = 200\\n\\npipeline[\\\"rfc\\\"].n_estimators = n_trees\\n\\npipeline_cv = GridSearchCV(\\n    pipeline,\\n    grid,\\n    verbose=1,\\n    n_jobs=-1,\\n    cv=2,\\n    # scoring=make_scorer(fbeta_score, beta=1.5, average=\\\"weighted\\\"),\\n)\\npipeline_cv.fit(X_train, y_train)\\n\\n\\nprint(pipeline_cv.score(X_train, y_train))\\nprint(pipeline_cv.score(X_test, y_test))\";\n",
       "                var nbb_formatted_code = \"num_cols = list(X.columns)\\n\\nbin_cols = []\\n\\ncat_cols = []\\ndrop_cats = []\\n\\n\\npreprocessing = ColumnTransformer(\\n    [\\n        # Scale numeric columns (not needed for all models but can't hurt)\\n        (\\\"scaler\\\", StandardScaler(), num_cols)\\n    ],\\n    remainder=\\\"passthrough\\\",\\n)\\n\\n\\npipeline = Pipeline(\\n    [\\n        (\\\"preprocessing\\\", preprocessing),\\n        (\\\"pca\\\", PCA(n_components=8)),\\n        # Choose your model and put it here\\n        (\\\"rfc\\\", RandomForestClassifier()),\\n    ]\\n)\\n\\n\\ngrid = {\\n    # Use model__ with hyperprammeter names after\\n    \\\"rfc__criterion\\\": [\\\"gini\\\", \\\"entropy\\\"],\\n    \\\"rfc__max_depth\\\": [10, 14, 20],\\n    \\\"rfc__min_samples_leaf\\\": [10, 16, 20],\\n}\\n\\nn_trees = 200\\n\\npipeline[\\\"rfc\\\"].n_estimators = n_trees\\n\\npipeline_cv = GridSearchCV(\\n    pipeline,\\n    grid,\\n    verbose=1,\\n    n_jobs=-1,\\n    cv=2,\\n    # scoring=make_scorer(fbeta_score, beta=1.5, average=\\\"weighted\\\"),\\n)\\npipeline_cv.fit(X_train, y_train)\\n\\n\\nprint(pipeline_cv.score(X_train, y_train))\\nprint(pipeline_cv.score(X_test, y_test))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_cols = list(X.columns)\n",
    "\n",
    "bin_cols = []\n",
    "\n",
    "cat_cols = []\n",
    "drop_cats = []\n",
    "\n",
    "\n",
    "preprocessing = ColumnTransformer(\n",
    "    [\n",
    "        # Scale numeric columns (not needed for all models but can't hurt)\n",
    "        (\"scaler\", StandardScaler(), num_cols)\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    ")\n",
    "\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"preprocessing\", preprocessing),\n",
    "        (\"pca\", PCA(n_components=8)),\n",
    "        # Choose your model and put it here\n",
    "        (\"rfc\", RandomForestClassifier()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "grid = {\n",
    "    # Use model__ with hyperprammeter names after\n",
    "    \"rfc__criterion\": [\"gini\", \"entropy\"],\n",
    "    \"rfc__max_depth\": [10, 14, 20],\n",
    "    \"rfc__min_samples_leaf\": [10, 16, 20],\n",
    "}\n",
    "\n",
    "n_trees = 200\n",
    "\n",
    "pipeline[\"rfc\"].n_estimators = n_trees\n",
    "\n",
    "pipeline_cv = GridSearchCV(\n",
    "    pipeline,\n",
    "    grid,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    cv=2,\n",
    "    # scoring=make_scorer(fbeta_score, beta=1.5, average=\"weighted\"),\n",
    ")\n",
    "pipeline_cv.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(pipeline_cv.score(X_train, y_train))\n",
    "print(pipeline_cv.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rfc__criterion': 'entropy',\n",
       " 'rfc__max_depth': 20,\n",
       " 'rfc__min_samples_leaf': 10}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"pipeline_cv.best_params_\";\n",
       "                var nbb_formatted_code = \"pipeline_cv.best_params_\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[105   1  22  11   2  15  17   0   9  18]\n",
      " [  3 169   3   0   0  20   0   0   1   4]\n",
      " [ 31   5  91  17   1  18   0   3  22  11]\n",
      " [ 15   0  15  85  14   5  16  21  11  18]\n",
      " [  8   0   4  13 130   1  13   7  21   3]\n",
      " [ 10  36  16   2   0 119   4   2   3   8]\n",
      " [  3   0   2  11  11   4 151   0   3  15]\n",
      " [  0   1   7   7   9  14   0 147  11   4]\n",
      " [ 16   0  14  11  22   6   1  10 116   4]\n",
      " [ 13   1  19  23   7  25  23  10  12  66]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       blues       0.51      0.53      0.52       200\n",
      "   classical       0.79      0.84      0.82       200\n",
      "     country       0.47      0.46      0.46       199\n",
      "       disco       0.47      0.42      0.45       200\n",
      "      hiphop       0.66      0.65      0.66       200\n",
      "        jazz       0.52      0.59      0.56       200\n",
      "       metal       0.67      0.76      0.71       200\n",
      "         pop       0.73      0.73      0.73       200\n",
      "      reggae       0.56      0.58      0.57       200\n",
      "        rock       0.44      0.33      0.38       199\n",
      "\n",
      "    accuracy                           0.59      1998\n",
      "   macro avg       0.58      0.59      0.59      1998\n",
      "weighted avg       0.58      0.59      0.59      1998\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"y_pred = pipeline_cv.predict(X_test)\\n\\nprint(confusion_matrix(y_test, y_pred))\\nprint(classification_report(y_test, y_pred))\";\n",
       "                var nbb_formatted_code = \"y_pred = pipeline_cv.predict(X_test)\\n\\nprint(confusion_matrix(y_test, y_pred))\\nprint(classification_report(y_test, y_pred))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = pipeline_cv.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
