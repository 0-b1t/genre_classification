{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%reload_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%reload_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"import warnings\\n\\nimport pandas as pd\\nimport numpy as np\\n\\nimport statsmodels.api as sm\\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\\n\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n\\nfrom sklearn.model_selection import train_test_split, GridSearchCV\\nfrom sklearn.metrics import (\\n    classification_report,\\n    confusion_matrix,\\n    fbeta_score,\\n    f1_score,\\n    make_scorer,\\n)\\n\\nfrom sklearn.pipeline import Pipeline\\nfrom sklearn.compose import ColumnTransformer\\nfrom sklearn.preprocessing import StandardScaler\\n\\nfrom sklearn.ensemble import RandomForestClassifier\\n\\n\\n%matplotlib inline\";\n",
       "                var nbb_formatted_code = \"import warnings\\n\\nimport pandas as pd\\nimport numpy as np\\n\\nimport statsmodels.api as sm\\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\\n\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n\\nfrom sklearn.model_selection import train_test_split, GridSearchCV\\nfrom sklearn.metrics import (\\n    classification_report,\\n    confusion_matrix,\\n    fbeta_score,\\n    f1_score,\\n    make_scorer,\\n)\\n\\nfrom sklearn.pipeline import Pipeline\\nfrom sklearn.compose import ColumnTransformer\\nfrom sklearn.preprocessing import StandardScaler\\n\\nfrom sklearn.ensemble import RandomForestClassifier\\n\\n\\n%matplotlib inline\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    fbeta_score,\n",
    "    f1_score,\n",
    "    make_scorer,\n",
    ")\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"def print_vif(x):\\n    \\\"\\\"\\\"Utility for checking multicollinearity assumption\\n    \\n    :param x: input features to check using VIF. This is assumed to be a pandas.DataFrame\\n    :return: nothing is returned the VIFs are printed as a pandas series\\n    \\\"\\\"\\\"\\n    # Silence numpy FutureWarning about .ptp\\n    with warnings.catch_warnings():\\n        warnings.simplefilter(\\\"ignore\\\")\\n        x = sm.add_constant(x)\\n\\n    vifs = []\\n    for i in range(x.shape[1]):\\n        vif = variance_inflation_factor(x.values, i)\\n        vifs.append(vif)\\n\\n    print(\\\"VIF results\\\\n-------------------------------\\\")\\n    print(pd.Series(vifs, index=x.columns))\\n    print(\\\"-------------------------------\\\\n\\\")\";\n",
       "                var nbb_formatted_code = \"def print_vif(x):\\n    \\\"\\\"\\\"Utility for checking multicollinearity assumption\\n    \\n    :param x: input features to check using VIF. This is assumed to be a pandas.DataFrame\\n    :return: nothing is returned the VIFs are printed as a pandas series\\n    \\\"\\\"\\\"\\n    # Silence numpy FutureWarning about .ptp\\n    with warnings.catch_warnings():\\n        warnings.simplefilter(\\\"ignore\\\")\\n        x = sm.add_constant(x)\\n\\n    vifs = []\\n    for i in range(x.shape[1]):\\n        vif = variance_inflation_factor(x.values, i)\\n        vifs.append(vif)\\n\\n    print(\\\"VIF results\\\\n-------------------------------\\\")\\n    print(pd.Series(vifs, index=x.columns))\\n    print(\\\"-------------------------------\\\\n\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def print_vif(x):\n",
    "    \"\"\"Utility for checking multicollinearity assumption\n",
    "    \n",
    "    :param x: input features to check using VIF. This is assumed to be a pandas.DataFrame\n",
    "    :return: nothing is returned the VIFs are printed as a pandas series\n",
    "    \"\"\"\n",
    "    # Silence numpy FutureWarning about .ptp\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        x = sm.add_constant(x)\n",
    "\n",
    "    vifs = []\n",
    "    for i in range(x.shape[1]):\n",
    "        vif = variance_inflation_factor(x.values, i)\n",
    "        vifs.append(vif)\n",
    "\n",
    "    print(\"VIF results\\n-------------------------------\")\n",
    "    print(pd.Series(vifs, index=x.columns))\n",
    "    print(\"-------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"feat_30_loc = \\\"../data/features_30_sec.csv\\\"\\nfeat_3_loc = \\\"../data/features_3_sec.csv\\\"\";\n",
       "                var nbb_formatted_code = \"feat_30_loc = \\\"../data/features_30_sec.csv\\\"\\nfeat_3_loc = \\\"../data/features_3_sec.csv\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feat_30_loc = \"../data/features_30_sec.csv\"\n",
    "feat_3_loc = \"../data/features_3_sec.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"# named long and short to differentiate easier\\nlong = pd.read_csv(feat_30_loc)\\nshort = pd.read_csv(feat_3_loc)\";\n",
       "                var nbb_formatted_code = \"# named long and short to differentiate easier\\nlong = pd.read_csv(feat_30_loc)\\nshort = pd.read_csv(feat_3_loc)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# named long and short to differentiate easier\n",
    "long = pd.read_csv(feat_30_loc)\n",
    "short = pd.read_csv(feat_3_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"# log transform the mfcc variance\\ncc_var_cols = [f\\\"mfcc{x}_var\\\" for x in range(1, 21)]\\nlogged_cc_var_df = short.copy()\\nfor col in cc_var_cols:\\n    logged_cc_var_df[col + \\\"_logged\\\"] = np.log(logged_cc_var_df[col])\\n    logged_cc_var_df = logged_cc_var_df.drop(col, 1)\";\n",
       "                var nbb_formatted_code = \"# log transform the mfcc variance\\ncc_var_cols = [f\\\"mfcc{x}_var\\\" for x in range(1, 21)]\\nlogged_cc_var_df = short.copy()\\nfor col in cc_var_cols:\\n    logged_cc_var_df[col + \\\"_logged\\\"] = np.log(logged_cc_var_df[col])\\n    logged_cc_var_df = logged_cc_var_df.drop(col, 1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# log transform the mfcc variance\n",
    "cc_var_cols = [f\"mfcc{x}_var\" for x in range(1, 21)]\n",
    "logged_cc_var_df = short.copy()\n",
    "for col in cc_var_cols:\n",
    "    logged_cc_var_df[col + \"_logged\"] = np.log(logged_cc_var_df[col])\n",
    "    logged_cc_var_df = logged_cc_var_df.drop(col, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"m_start = 12  # highest mfcc to use. higher than this is too high in the frequency spectrum to really matter\\nmel_freq_drops = [f\\\"mfcc{x}_mean\\\" for x in range(m_start, 21)] + [\\n    f\\\"mfcc{x}_var_logged\\\" for x in range(m_start, 21)\\n]\";\n",
       "                var nbb_formatted_code = \"m_start = 12  # highest mfcc to use. higher than this is too high in the frequency spectrum to really matter\\nmel_freq_drops = [f\\\"mfcc{x}_mean\\\" for x in range(m_start, 21)] + [\\n    f\\\"mfcc{x}_var_logged\\\" for x in range(m_start, 21)\\n]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m_start = 12  # highest mfcc to use. higher than this is too high in the frequency spectrum to really matter\n",
    "mel_freq_drops = [f\"mfcc{x}_mean\" for x in range(m_start, 21)] + [\n",
    "    f\"mfcc{x}_var_logged\" for x in range(m_start, 21)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIF results\n",
      "-------------------------------\n",
      "const                      776.274686\n",
      "chroma_stft_mean             3.391661\n",
      "chroma_stft_var              2.546500\n",
      "rms_mean                     7.666024\n",
      "rms_var                      3.268666\n",
      "zero_crossing_rate_mean      6.949903\n",
      "zero_crossing_rate_var       2.660002\n",
      "harmony_mean                 1.478593\n",
      "perceptr_mean                1.573693\n",
      "perceptr_var                 4.918247\n",
      "tempo                        1.009578\n",
      "mfcc1_mean                   7.258845\n",
      "mfcc2_mean                   5.652443\n",
      "mfcc3_mean                   2.547365\n",
      "mfcc4_mean                   2.076686\n",
      "mfcc5_mean                   2.679961\n",
      "mfcc6_mean                   3.340509\n",
      "mfcc7_mean                   3.014978\n",
      "mfcc8_mean                   3.704902\n",
      "mfcc9_mean                   2.584736\n",
      "mfcc10_mean                  2.548987\n",
      "mfcc11_mean                  2.098440\n",
      "mfcc1_var_logged             2.949586\n",
      "mfcc2_var_logged             2.583133\n",
      "mfcc3_var_logged             2.590872\n",
      "mfcc4_var_logged             2.861840\n",
      "mfcc5_var_logged             2.904229\n",
      "mfcc6_var_logged             3.055790\n",
      "mfcc7_var_logged             2.831330\n",
      "mfcc8_var_logged             2.573452\n",
      "mfcc9_var_logged             2.384232\n",
      "mfcc10_var_logged            2.240260\n",
      "mfcc11_var_logged            2.079300\n",
      "dtype: float64\n",
      "-------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"# best balance for VIF I could tune\\ndrop_cols = [\\n    \\\"length\\\",\\n    \\\"filename\\\",\\n    \\\"label\\\",\\n    #     \\\"zero_crossing_rate_mean\\\",\\n    #     \\\"zero_crossing_rate_var\\\",\\n    \\\"rolloff_mean\\\",\\n    \\\"harmony_var\\\",\\n    \\\"rolloff_var\\\",\\n    \\\"spectral_centroid_var\\\",\\n    \\\"spectral_bandwidth_var\\\",\\n    \\\"spectral_centroid_mean\\\",\\n    \\\"spectral_bandwidth_mean\\\",\\n    #     \\\"rms_mean\\\",\\n    #     \\\"rms_var\\\",\\n]\\ndrop_cols = drop_cols + mel_freq_drops\\nprint_vif(logged_cc_var_df.drop(drop_cols, 1,))\";\n",
       "                var nbb_formatted_code = \"# best balance for VIF I could tune\\ndrop_cols = [\\n    \\\"length\\\",\\n    \\\"filename\\\",\\n    \\\"label\\\",\\n    #     \\\"zero_crossing_rate_mean\\\",\\n    #     \\\"zero_crossing_rate_var\\\",\\n    \\\"rolloff_mean\\\",\\n    \\\"harmony_var\\\",\\n    \\\"rolloff_var\\\",\\n    \\\"spectral_centroid_var\\\",\\n    \\\"spectral_bandwidth_var\\\",\\n    \\\"spectral_centroid_mean\\\",\\n    \\\"spectral_bandwidth_mean\\\",\\n    #     \\\"rms_mean\\\",\\n    #     \\\"rms_var\\\",\\n]\\ndrop_cols = drop_cols + mel_freq_drops\\nprint_vif(logged_cc_var_df.drop(drop_cols, 1,))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# best balance for VIF I could tune\n",
    "drop_cols = [\n",
    "    \"length\",\n",
    "    \"filename\",\n",
    "    \"label\",\n",
    "    #     \"zero_crossing_rate_mean\",\n",
    "    #     \"zero_crossing_rate_var\",\n",
    "    \"rolloff_mean\",\n",
    "    \"harmony_var\",\n",
    "    \"rolloff_var\",\n",
    "    \"spectral_centroid_var\",\n",
    "    \"spectral_bandwidth_var\",\n",
    "    \"spectral_centroid_mean\",\n",
    "    \"spectral_bandwidth_mean\",\n",
    "    #     \"rms_mean\",\n",
    "    #     \"rms_var\",\n",
    "]\n",
    "drop_cols = drop_cols + mel_freq_drops\n",
    "print_vif(logged_cc_var_df.drop(drop_cols, 1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"X = logged_cc_var_df.drop(drop_cols, 1,)\\ny = logged_cc_var_df[\\\"label\\\"]\\n\\nX_train, X_test, y_train, y_test = train_test_split(\\n    X, y, test_size=0.2, random_state=34, stratify=y\\n)\";\n",
       "                var nbb_formatted_code = \"X = logged_cc_var_df.drop(drop_cols, 1,)\\ny = logged_cc_var_df[\\\"label\\\"]\\n\\nX_train, X_test, y_train, y_test = train_test_split(\\n    X, y, test_size=0.2, random_state=34, stratify=y\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = logged_cc_var_df.drop(drop_cols, 1,)\n",
    "y = logged_cc_var_df[\"label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=34, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 18 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:   24.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9062812812812813\n",
      "0.7827827827827828\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"num_cols = list(X.columns)\\n\\nbin_cols = []\\n\\ncat_cols = []\\ndrop_cats = []\\n\\n\\npreprocessing = ColumnTransformer(\\n    [\\n        # Scale numeric columns (not needed for all models but can't hurt)\\n        (\\\"scaler\\\", StandardScaler(), num_cols)\\n    ],\\n    remainder=\\\"passthrough\\\",\\n)\\n\\n\\npipeline = Pipeline(\\n    [\\n        (\\\"preprocessing\\\", preprocessing),\\n        # Choose your model and put it here\\n        (\\\"rfc\\\", RandomForestClassifier()),\\n    ]\\n)\\n\\n\\ngrid = {\\n    # Use model__ with hyperprammeter names after\\n    \\\"rfc__criterion\\\": [\\\"gini\\\", \\\"entropy\\\"],\\n    \\\"rfc__max_depth\\\": [10, 14, 20],\\n    \\\"rfc__min_samples_leaf\\\": [10, 16, 20],\\n}\\n\\nn_trees = 200\\n\\npipeline[\\\"rfc\\\"].n_estimators = n_trees\\n\\npipeline_cv = GridSearchCV(\\n    pipeline,\\n    grid,\\n    verbose=1,\\n    n_jobs=-1,\\n    cv=2,\\n    #scoring=make_scorer(fbeta_score, beta=1.5, average=\\\"weighted\\\"),\\n)\\npipeline_cv.fit(X_train, y_train)\\n\\n\\nprint(pipeline_cv.score(X_train, y_train))\\nprint(pipeline_cv.score(X_test, y_test))\";\n",
       "                var nbb_formatted_code = \"num_cols = list(X.columns)\\n\\nbin_cols = []\\n\\ncat_cols = []\\ndrop_cats = []\\n\\n\\npreprocessing = ColumnTransformer(\\n    [\\n        # Scale numeric columns (not needed for all models but can't hurt)\\n        (\\\"scaler\\\", StandardScaler(), num_cols)\\n    ],\\n    remainder=\\\"passthrough\\\",\\n)\\n\\n\\npipeline = Pipeline(\\n    [\\n        (\\\"preprocessing\\\", preprocessing),\\n        # Choose your model and put it here\\n        (\\\"rfc\\\", RandomForestClassifier()),\\n    ]\\n)\\n\\n\\ngrid = {\\n    # Use model__ with hyperprammeter names after\\n    \\\"rfc__criterion\\\": [\\\"gini\\\", \\\"entropy\\\"],\\n    \\\"rfc__max_depth\\\": [10, 14, 20],\\n    \\\"rfc__min_samples_leaf\\\": [10, 16, 20],\\n}\\n\\nn_trees = 200\\n\\npipeline[\\\"rfc\\\"].n_estimators = n_trees\\n\\npipeline_cv = GridSearchCV(\\n    pipeline,\\n    grid,\\n    verbose=1,\\n    n_jobs=-1,\\n    cv=2,\\n    # scoring=make_scorer(fbeta_score, beta=1.5, average=\\\"weighted\\\"),\\n)\\npipeline_cv.fit(X_train, y_train)\\n\\n\\nprint(pipeline_cv.score(X_train, y_train))\\nprint(pipeline_cv.score(X_test, y_test))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_cols = list(X.columns)\n",
    "\n",
    "bin_cols = []\n",
    "\n",
    "cat_cols = []\n",
    "drop_cats = []\n",
    "\n",
    "\n",
    "preprocessing = ColumnTransformer(\n",
    "    [\n",
    "        # Scale numeric columns (not needed for all models but can't hurt)\n",
    "        (\"scaler\", StandardScaler(), num_cols)\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    ")\n",
    "\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"preprocessing\", preprocessing),\n",
    "        # Choose your model and put it here\n",
    "        (\"rfc\", RandomForestClassifier()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "grid = {\n",
    "    # Use model__ with hyperprammeter names after\n",
    "    \"rfc__criterion\": [\"gini\", \"entropy\"],\n",
    "    \"rfc__max_depth\": [10, 14, 20],\n",
    "    \"rfc__min_samples_leaf\": [10, 16, 20],\n",
    "}\n",
    "\n",
    "n_trees = 200\n",
    "\n",
    "pipeline[\"rfc\"].n_estimators = n_trees\n",
    "\n",
    "pipeline_cv = GridSearchCV(\n",
    "    pipeline,\n",
    "    grid,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    cv=2,\n",
    "    # scoring=make_scorer(fbeta_score, beta=1.5, average=\"weighted\"),\n",
    ")\n",
    "pipeline_cv.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(pipeline_cv.score(X_train, y_train))\n",
    "print(pipeline_cv.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rfc__criterion': 'entropy',\n",
       " 'rfc__max_depth': 20,\n",
       " 'rfc__min_samples_leaf': 10}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"pipeline_cv.best_params_\";\n",
       "                var nbb_formatted_code = \"pipeline_cv.best_params_\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[169   0   8   3   1   5   6   0   6   2]\n",
      " [  0 187   2   0   0  10   0   0   1   0]\n",
      " [ 15   0 144   5   0  21   0   0  10   4]\n",
      " [  0   1   4 157   4   3   3   3  10  15]\n",
      " [  5   0   3   7 152   0   3  17  13   0]\n",
      " [  5  11   5   1   0 178   0   0   0   0]\n",
      " [  3   0   2   2   1   2 177   0   5   8]\n",
      " [  0   1  15   6   6   5   1 152  10   4]\n",
      " [  8   1   7   4   9   1   1   7 160   2]\n",
      " [ 13   4  16  19   0  16   7   1  11 112]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       blues       0.78      0.84      0.81       200\n",
      "   classical       0.91      0.94      0.92       200\n",
      "     country       0.70      0.72      0.71       199\n",
      "       disco       0.77      0.79      0.78       200\n",
      "      hiphop       0.88      0.76      0.82       200\n",
      "        jazz       0.74      0.89      0.81       200\n",
      "       metal       0.89      0.89      0.89       200\n",
      "         pop       0.84      0.76      0.80       200\n",
      "      reggae       0.71      0.80      0.75       200\n",
      "        rock       0.76      0.56      0.65       199\n",
      "\n",
      "    accuracy                           0.79      1998\n",
      "   macro avg       0.80      0.79      0.79      1998\n",
      "weighted avg       0.80      0.79      0.79      1998\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"y_pred = pipeline_cv.predict(X_test)\\n\\nprint(confusion_matrix(y_test, y_pred))\\nprint(classification_report(y_test, y_pred))\";\n",
       "                var nbb_formatted_code = \"y_pred = pipeline_cv.predict(X_test)\\n\\nprint(confusion_matrix(y_test, y_pred))\\nprint(classification_report(y_test, y_pred))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = pipeline_cv.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
