{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%reload_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%reload_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"import warnings\\n\\nimport pandas as pd\\nimport numpy as np\\nimport pickle\\n\\nimport statsmodels.api as sm\\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\\n\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n\\nfrom sklearn.model_selection import train_test_split, GridSearchCV\\nfrom sklearn.metrics import (\\n    classification_report,\\n    confusion_matrix,\\n    fbeta_score,\\n    f1_score,\\n    make_scorer,\\n    accuracy_score,\\n)\\n\\nfrom sklearn.pipeline import Pipeline\\nfrom sklearn.compose import ColumnTransformer\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.decomposition import PCA\\n\\nfrom xgboost import XGBClassifier\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.svm import SVC\";\n",
       "                var nbb_formatted_code = \"import warnings\\n\\nimport pandas as pd\\nimport numpy as np\\nimport pickle\\n\\nimport statsmodels.api as sm\\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\\n\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n\\nfrom sklearn.model_selection import train_test_split, GridSearchCV\\nfrom sklearn.metrics import (\\n    classification_report,\\n    confusion_matrix,\\n    fbeta_score,\\n    f1_score,\\n    make_scorer,\\n    accuracy_score,\\n)\\n\\nfrom sklearn.pipeline import Pipeline\\nfrom sklearn.compose import ColumnTransformer\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.decomposition import PCA\\n\\nfrom xgboost import XGBClassifier\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.svm import SVC\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    fbeta_score,\n",
    "    f1_score,\n",
    "    make_scorer,\n",
    "    accuracy_score,\n",
    ")\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"def print_vif(x):\\n    \\\"\\\"\\\"Utility for checking multicollinearity assumption\\n    \\n    :param x: input features to check using VIF. This is assumed to be a pandas.DataFrame\\n    :return: nothing is returned the VIFs are printed as a pandas series\\n    \\\"\\\"\\\"\\n    # Silence numpy FutureWarning about .ptp\\n    with warnings.catch_warnings():\\n        warnings.simplefilter(\\\"ignore\\\")\\n        x = sm.add_constant(x)\\n\\n    vifs = []\\n    for i in range(x.shape[1]):\\n        vif = variance_inflation_factor(x.values, i)\\n        vifs.append(vif)\\n\\n    print(\\\"VIF results\\\\n-------------------------------\\\")\\n    print(pd.Series(vifs, index=x.columns))\\n    print(\\\"-------------------------------\\\\n\\\")\";\n",
       "                var nbb_formatted_code = \"def print_vif(x):\\n    \\\"\\\"\\\"Utility for checking multicollinearity assumption\\n    \\n    :param x: input features to check using VIF. This is assumed to be a pandas.DataFrame\\n    :return: nothing is returned the VIFs are printed as a pandas series\\n    \\\"\\\"\\\"\\n    # Silence numpy FutureWarning about .ptp\\n    with warnings.catch_warnings():\\n        warnings.simplefilter(\\\"ignore\\\")\\n        x = sm.add_constant(x)\\n\\n    vifs = []\\n    for i in range(x.shape[1]):\\n        vif = variance_inflation_factor(x.values, i)\\n        vifs.append(vif)\\n\\n    print(\\\"VIF results\\\\n-------------------------------\\\")\\n    print(pd.Series(vifs, index=x.columns))\\n    print(\\\"-------------------------------\\\\n\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def print_vif(x):\n",
    "    \"\"\"Utility for checking multicollinearity assumption\n",
    "    \n",
    "    :param x: input features to check using VIF. This is assumed to be a pandas.DataFrame\n",
    "    :return: nothing is returned the VIFs are printed as a pandas series\n",
    "    \"\"\"\n",
    "    # Silence numpy FutureWarning about .ptp\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        x = sm.add_constant(x)\n",
    "\n",
    "    vifs = []\n",
    "    for i in range(x.shape[1]):\n",
    "        vif = variance_inflation_factor(x.values, i)\n",
    "        vifs.append(vif)\n",
    "\n",
    "    print(\"VIF results\\n-------------------------------\")\n",
    "    print(pd.Series(vifs, index=x.columns))\n",
    "    print(\"-------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"# To use all\\n# df_long = pd.read_csv(\\\"../data/features_30_sec.csv\\\")\\n# df_short = pd.read_csv(\\\"../data/features_3_sec.csv\\\")\\n# df = pd.concat((df_long, df_short))\\n\\n# To use just one\\n# df = pd.read_csv(\\\"../data/features_30_sec.csv\\\")\\ndf = pd.read_csv(\\\"../data/features_3_sec.csv\\\")\\n\\ndf[\\\"genre\\\"] = df[\\\"filename\\\"].str.split(\\\".\\\").str[0]\\n\\n# \\\"blues.00000.0.wav\\\" -> \\\"blues.00000\\\"\\n# and\\n# \\\"blues.00000.wav\\\" -> \\\"blues.00000\\\"\\n# logic: split on period, take first 2 elements, and but back together\\ndf[\\\"songname\\\"] = df[\\\"filename\\\"].str.split(\\\".\\\").str[:2].str.join(\\\".\\\")\";\n",
       "                var nbb_formatted_code = \"# To use all\\n# df_long = pd.read_csv(\\\"../data/features_30_sec.csv\\\")\\n# df_short = pd.read_csv(\\\"../data/features_3_sec.csv\\\")\\n# df = pd.concat((df_long, df_short))\\n\\n# To use just one\\n# df = pd.read_csv(\\\"../data/features_30_sec.csv\\\")\\ndf = pd.read_csv(\\\"../data/features_3_sec.csv\\\")\\n\\ndf[\\\"genre\\\"] = df[\\\"filename\\\"].str.split(\\\".\\\").str[0]\\n\\n# \\\"blues.00000.0.wav\\\" -> \\\"blues.00000\\\"\\n# and\\n# \\\"blues.00000.wav\\\" -> \\\"blues.00000\\\"\\n# logic: split on period, take first 2 elements, and but back together\\ndf[\\\"songname\\\"] = df[\\\"filename\\\"].str.split(\\\".\\\").str[:2].str.join(\\\".\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To use all\n",
    "# df_long = pd.read_csv(\"../data/features_30_sec.csv\")\n",
    "# df_short = pd.read_csv(\"../data/features_3_sec.csv\")\n",
    "# df = pd.concat((df_long, df_short))\n",
    "\n",
    "# To use just one\n",
    "# df = pd.read_csv(\"../data/features_30_sec.csv\")\n",
    "df = pd.read_csv(\"../data/features_3_sec.csv\")\n",
    "\n",
    "df[\"genre\"] = df[\"filename\"].str.split(\".\").str[0]\n",
    "\n",
    "# \"blues.00000.0.wav\" -> \"blues.00000\"\n",
    "# and\n",
    "# \"blues.00000.wav\" -> \"blues.00000\"\n",
    "# logic: split on period, take first 2 elements, and but back together\n",
    "df[\"songname\"] = df[\"filename\"].str.split(\".\").str[:2].str.join(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"m_start = 10  # highest mfcc to use. higher than this is too high in the frequency spectrum to really matter\\nmel_freq_drops = [f\\\"mfcc{x}_mean\\\" for x in range(m_start, 21)] + [\\n    f\\\"mfcc{x}_var\\\" for x in range(m_start, 21)\\n]\";\n",
       "                var nbb_formatted_code = \"m_start = 10  # highest mfcc to use. higher than this is too high in the frequency spectrum to really matter\\nmel_freq_drops = [f\\\"mfcc{x}_mean\\\" for x in range(m_start, 21)] + [\\n    f\\\"mfcc{x}_var\\\" for x in range(m_start, 21)\\n]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m_start = 10  # highest mfcc to use. higher than this is too high in the frequency spectrum to really matter\n",
    "mel_freq_drops = [f\"mfcc{x}_mean\" for x in range(m_start, 21)] + [\n",
    "    f\"mfcc{x}_var\" for x in range(m_start, 21)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"drop_cols = [\\n    \\\"filename\\\",\\n    \\\"label\\\",\\n    \\\"genre\\\",\\n    \\\"songname\\\",\\n    \\\"length\\\",\\n    \\\"chroma_stft_mean\\\",\\n    \\\"chroma_stft_var\\\",\\n    \\\"rms_mean\\\",\\n    \\\"rms_var\\\",\\n    \\\"spectral_centroid_mean\\\",\\n    \\\"spectral_centroid_var\\\",\\n    \\\"spectral_bandwidth_mean\\\",\\n    \\\"spectral_bandwidth_var\\\",\\n    \\\"rolloff_mean\\\",\\n    \\\"rolloff_var\\\",\\n    #     \\\"zero_crossing_rate_mean\\\",\\n    #     \\\"zero_crossing_rate_var\\\",\\n    #     \\\"harmony_mean\\\",\\n    #     \\\"harmony_var\\\",\\n    #     \\\"perceptr_mean\\\",\\n    \\\"perceptr_var\\\",\\n    #     \\\"tempo\\\",\\n]\\n\\ndrop_cols = drop_cols + mel_freq_drops\\n# print_vif(df.drop(drop_cols, 1,))\";\n",
       "                var nbb_formatted_code = \"drop_cols = [\\n    \\\"filename\\\",\\n    \\\"label\\\",\\n    \\\"genre\\\",\\n    \\\"songname\\\",\\n    \\\"length\\\",\\n    \\\"chroma_stft_mean\\\",\\n    \\\"chroma_stft_var\\\",\\n    \\\"rms_mean\\\",\\n    \\\"rms_var\\\",\\n    \\\"spectral_centroid_mean\\\",\\n    \\\"spectral_centroid_var\\\",\\n    \\\"spectral_bandwidth_mean\\\",\\n    \\\"spectral_bandwidth_var\\\",\\n    \\\"rolloff_mean\\\",\\n    \\\"rolloff_var\\\",\\n    #     \\\"zero_crossing_rate_mean\\\",\\n    #     \\\"zero_crossing_rate_var\\\",\\n    #     \\\"harmony_mean\\\",\\n    #     \\\"harmony_var\\\",\\n    #     \\\"perceptr_mean\\\",\\n    \\\"perceptr_var\\\",\\n    #     \\\"tempo\\\",\\n]\\n\\ndrop_cols = drop_cols + mel_freq_drops\\n# print_vif(df.drop(drop_cols, 1,))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "drop_cols = [\n",
    "    \"filename\",\n",
    "    \"label\",\n",
    "    \"genre\",\n",
    "    \"songname\",\n",
    "    \"length\",\n",
    "    \"chroma_stft_mean\",\n",
    "    \"chroma_stft_var\",\n",
    "    \"rms_mean\",\n",
    "    \"rms_var\",\n",
    "    \"spectral_centroid_mean\",\n",
    "    \"spectral_centroid_var\",\n",
    "    \"spectral_bandwidth_mean\",\n",
    "    \"spectral_bandwidth_var\",\n",
    "    \"rolloff_mean\",\n",
    "    \"rolloff_var\",\n",
    "    #     \"zero_crossing_rate_mean\",\n",
    "    #     \"zero_crossing_rate_var\",\n",
    "    #     \"harmony_mean\",\n",
    "    #     \"harmony_var\",\n",
    "    #     \"perceptr_mean\",\n",
    "    \"perceptr_var\",\n",
    "    #     \"tempo\",\n",
    "]\n",
    "\n",
    "drop_cols = drop_cols + mel_freq_drops\n",
    "# print_vif(df.drop(drop_cols, 1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"# X = df.drop(columns=drop_cols + [\\\"genre\\\"])\\nX = df.drop(drop_cols, 1)\\ny = df[\\\"genre\\\"]\";\n",
       "                var nbb_formatted_code = \"# X = df.drop(columns=drop_cols + [\\\"genre\\\"])\\nX = df.drop(drop_cols, 1)\\ny = df[\\\"genre\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# X = df.drop(columns=drop_cols + [\"genre\"])\n",
    "X = df.drop(drop_cols, 1)\n",
    "y = df[\"genre\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"X_logged = X.copy()\\nfor c in X_logged:\\n    if c.endswith(\\\"_var\\\"):\\n        X_logged[c] = np.log(X_logged[c])\";\n",
       "                var nbb_formatted_code = \"X_logged = X.copy()\\nfor c in X_logged:\\n    if c.endswith(\\\"_var\\\"):\\n        X_logged[c] = np.log(X_logged[c])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_logged = X.copy()\n",
    "for c in X_logged:\n",
    "    if c.endswith(\"_var\"):\n",
    "        X_logged[c] = np.log(X_logged[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIF results\n",
      "-------------------------------\n",
      "const                      179.520374\n",
      "zero_crossing_rate_mean      5.515683\n",
      "zero_crossing_rate_var       2.654780\n",
      "harmony_mean                 1.463564\n",
      "harmony_var                  1.834723\n",
      "perceptr_mean                1.558186\n",
      "tempo                        1.007095\n",
      "mfcc1_mean                   3.120024\n",
      "mfcc1_var                    1.952657\n",
      "mfcc2_mean                   5.215105\n",
      "mfcc2_var                    2.124468\n",
      "mfcc3_mean                   2.420531\n",
      "mfcc3_var                    1.988724\n",
      "mfcc4_mean                   1.992960\n",
      "mfcc4_var                    2.148103\n",
      "mfcc5_mean                   2.509799\n",
      "mfcc5_var                    2.061580\n",
      "mfcc6_mean                   3.093166\n",
      "mfcc6_var                    2.277700\n",
      "mfcc7_mean                   2.834846\n",
      "mfcc7_var                    2.087279\n",
      "mfcc8_mean                   2.977315\n",
      "mfcc8_var                    2.045695\n",
      "mfcc9_mean                   2.358157\n",
      "mfcc9_var                    1.860646\n",
      "dtype: float64\n",
      "-------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"print_vif(X)\";\n",
       "                var nbb_formatted_code = \"print_vif(X)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_vif(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7990, 24) (7990,)\n",
      "(2000, 24) (2000,)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"# og: \\\"blues.00000.0.wav\\\"\\n# songname: \\\"blues.00000\\\"\\n# genre: \\\"blues\\\"\\nsong_genre = df[[\\\"songname\\\", \\\"genre\\\"]].drop_duplicates()\\n\\ntrain_songs, test_songs = train_test_split(\\n    song_genre[\\\"songname\\\"], test_size=0.2, random_state=42, stratify=song_genre[\\\"genre\\\"]\\n)\\n\\ntrain_songs = pickle.load(open(\\\"../data/train_songs.p\\\", \\\"rb\\\"))\\ntest_songs = pickle.load(open(\\\"../data/test_songs.p\\\", \\\"rb\\\"))\\n\\ntrain_idxs = df[df[\\\"songname\\\"].isin(train_songs)].index\\ntest_idxs = df[df[\\\"songname\\\"].isin(test_songs)].index\\n\\nX_train = X_logged.loc[train_idxs, :]\\nX_test = X_logged.loc[test_idxs, :]\\ny_train = y[train_idxs]\\ny_test = y[test_idxs]\\n\\nprint(X_train.shape, y_train.shape)\\nprint(X_test.shape, y_test.shape)\";\n",
       "                var nbb_formatted_code = \"# og: \\\"blues.00000.0.wav\\\"\\n# songname: \\\"blues.00000\\\"\\n# genre: \\\"blues\\\"\\nsong_genre = df[[\\\"songname\\\", \\\"genre\\\"]].drop_duplicates()\\n\\ntrain_songs, test_songs = train_test_split(\\n    song_genre[\\\"songname\\\"], test_size=0.2, random_state=42, stratify=song_genre[\\\"genre\\\"]\\n)\\n\\ntrain_songs = pickle.load(open(\\\"../data/train_songs.p\\\", \\\"rb\\\"))\\ntest_songs = pickle.load(open(\\\"../data/test_songs.p\\\", \\\"rb\\\"))\\n\\ntrain_idxs = df[df[\\\"songname\\\"].isin(train_songs)].index\\ntest_idxs = df[df[\\\"songname\\\"].isin(test_songs)].index\\n\\nX_train = X_logged.loc[train_idxs, :]\\nX_test = X_logged.loc[test_idxs, :]\\ny_train = y[train_idxs]\\ny_test = y[test_idxs]\\n\\nprint(X_train.shape, y_train.shape)\\nprint(X_test.shape, y_test.shape)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# og: \"blues.00000.0.wav\"\n",
    "# songname: \"blues.00000\"\n",
    "# genre: \"blues\"\n",
    "song_genre = df[[\"songname\", \"genre\"]].drop_duplicates()\n",
    "\n",
    "train_songs, test_songs = train_test_split(\n",
    "    song_genre[\"songname\"], test_size=0.2, random_state=42, stratify=song_genre[\"genre\"]\n",
    ")\n",
    "\n",
    "train_songs = pickle.load(open(\"../data/train_songs.p\", \"rb\"))\n",
    "test_songs = pickle.load(open(\"../data/test_songs.p\", \"rb\"))\n",
    "\n",
    "train_idxs = df[df[\"songname\"].isin(train_songs)].index\n",
    "test_idxs = df[df[\"songname\"].isin(test_songs)].index\n",
    "\n",
    "X_train = X_logged.loc[train_idxs, :]\n",
    "X_test = X_logged.loc[test_idxs, :]\n",
    "y_train = y[train_idxs]\n",
    "y_test = y[test_idxs]\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"# Prove no overlap of songs between train/test\\nset(train_songs).intersection(set(test_songs))\";\n",
       "                var nbb_formatted_code = \"# Prove no overlap of songs between train/test\\nset(train_songs).intersection(set(test_songs))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prove no overlap of songs between train/test\n",
    "set(train_songs).intersection(set(test_songs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 36 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed:   39.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9322903629536922\n",
      "0.641\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'svc__C': 10,\n",
       " 'svc__decision_function_shape': 'ovo',\n",
       " 'svc__degree': 5,\n",
       " 'svc__kernel': 'poly'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"num_cols = list(X.columns)\\n\\nbin_cols = []\\n\\ncat_cols = []\\ndrop_cats = []\\n\\n\\npreprocessing = ColumnTransformer(\\n    [\\n        # Scale numeric columns (not needed for all models but can't hurt)\\n        (\\\"scaler\\\", StandardScaler(), num_cols)\\n    ],\\n    remainder=\\\"passthrough\\\",\\n)\\n\\n\\npipeline = Pipeline(\\n    [\\n        (\\\"preprocessing\\\", preprocessing),\\n        #         (\\\"pca\\\", PCA(n_components=10)),\\n        # Choose your model and put it here\\n        (\\\"svc\\\", SVC()),\\n    ]\\n)\\n\\n\\ngrid = {\\n    # Use model__ with hyperprammeter names after\\n    \\\"svc__C\\\": [1, 10, 100],\\n    \\\"svc__kernel\\\": [\\\"linear\\\", 'poly'],\\n    \\\"svc__decision_function_shape\\\": [\\\"ovo\\\", \\\"ovr\\\"],\\n    \\\"svc__degree\\\": [2, 3, 5],\\n}\\n\\n\\npipeline_cv = GridSearchCV(pipeline, grid, verbose=1, n_jobs=-1, cv=2)\\npipeline_cv.fit(X_train, y_train)\\n\\n\\nprint(pipeline_cv.score(X_train, y_train))\\nprint(pipeline_cv.score(X_test, y_test))\\npipeline_cv.best_params_\";\n",
       "                var nbb_formatted_code = \"num_cols = list(X.columns)\\n\\nbin_cols = []\\n\\ncat_cols = []\\ndrop_cats = []\\n\\n\\npreprocessing = ColumnTransformer(\\n    [\\n        # Scale numeric columns (not needed for all models but can't hurt)\\n        (\\\"scaler\\\", StandardScaler(), num_cols)\\n    ],\\n    remainder=\\\"passthrough\\\",\\n)\\n\\n\\npipeline = Pipeline(\\n    [\\n        (\\\"preprocessing\\\", preprocessing),\\n        #         (\\\"pca\\\", PCA(n_components=10)),\\n        # Choose your model and put it here\\n        (\\\"svc\\\", SVC()),\\n    ]\\n)\\n\\n\\ngrid = {\\n    # Use model__ with hyperprammeter names after\\n    \\\"svc__C\\\": [1, 10, 100],\\n    \\\"svc__kernel\\\": [\\\"linear\\\", \\\"poly\\\"],\\n    \\\"svc__decision_function_shape\\\": [\\\"ovo\\\", \\\"ovr\\\"],\\n    \\\"svc__degree\\\": [2, 3, 5],\\n}\\n\\n\\npipeline_cv = GridSearchCV(pipeline, grid, verbose=1, n_jobs=-1, cv=2)\\npipeline_cv.fit(X_train, y_train)\\n\\n\\nprint(pipeline_cv.score(X_train, y_train))\\nprint(pipeline_cv.score(X_test, y_test))\\npipeline_cv.best_params_\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_cols = list(X.columns)\n",
    "\n",
    "bin_cols = []\n",
    "\n",
    "cat_cols = []\n",
    "drop_cats = []\n",
    "\n",
    "\n",
    "preprocessing = ColumnTransformer(\n",
    "    [\n",
    "        # Scale numeric columns (not needed for all models but can't hurt)\n",
    "        (\"scaler\", StandardScaler(), num_cols)\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    ")\n",
    "\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"preprocessing\", preprocessing),\n",
    "        #         (\"pca\", PCA(n_components=10)),\n",
    "        # Choose your model and put it here\n",
    "        (\"svc\", SVC()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "grid = {\n",
    "    # Use model__ with hyperprammeter names after\n",
    "    \"svc__C\": [1, 10, 100],\n",
    "    \"svc__kernel\": [\"linear\"],\n",
    "    \"svc__decision_function_shape\": [\"ovo\", \"ovr\"],\n",
    "   # \"svc__degree\": [2, 3, 5],\n",
    "}\n",
    "\n",
    "\n",
    "pipeline_cv = GridSearchCV(pipeline, grid, verbose=1, n_jobs=-1, cv=2)\n",
    "pipeline_cv.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(pipeline_cv.score(X_train, y_train))\n",
    "print(pipeline_cv.score(X_test, y_test))\n",
    "pipeline_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'svc__C': 10,\n",
       " 'svc__decision_function_shape': 'ovo',\n",
       " 'svc__degree': 2,\n",
       " 'svc__kernel': 'rbf'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"pipeline_cv.best_params_\";\n",
       "                var nbb_formatted_code = \"pipeline_cv.best_params_\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline_cv.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
