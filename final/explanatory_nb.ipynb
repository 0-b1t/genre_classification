{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%reload_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%reload_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext nb_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genre Classification\n",
    "\n",
    "Supervised learning to predict genre classification based on spectral analysis.\n",
    "\n",
    "[DATA](https://www.kaggle.com/andradaolteanu/gtzan-dataset-music-genre-classification) Taken from Kaggle\n",
    "\n",
    "There are two sets. One is the original 30 sec clips and all their features. The other is those same 30 sec clips broken down into 10 separate 3 second clips and analyzed on their own.\n",
    "\n",
    "[Original Files](https://web.archive.org/web/20200812034358/http://marsyas.info/downloads/datasets.html) Must use the Internet Archive Wayback Machine because the website is no longer available\n",
    "\n",
    "### Feature explanation\n",
    "\n",
    "The documentation on the Kaggle website is quite sparse. This is the best explanation I could come up with while looking around at other MIR resources (Music Information Retrieval)\n",
    "\n",
    "The data set itself is not clear but I am assuming that each mean and variance is for an array for each subsections. That means each subsection is further broken down and the variables are generated for that subsection and then take the mean over the three second interval.\n",
    "\n",
    "length - measured in ms. Same for every entry. Not useful\n",
    "\n",
    "chroma_stft - Chromagram that breaks down the frequency spectrum. I believe this corresponds to the images generated from the original data set.\n",
    "\n",
    "rms - RMS in relation to the frequency spectrum\n",
    "\n",
    "spectral_centroid - The 'center' of the frequency spectrum. Higher values imply 'brighter' sounding songs\n",
    "\n",
    "spectral_bandwidth - Use in relation with the centroid. How much of the spectrum contributes to the centroid\n",
    "\n",
    "rolloff - A certain percentage of the total energy in the signal comes from frequencies below this value\n",
    "\n",
    "zero_crossing_rate - Audio files are an array of values from -1 to 1. This is the rate at which the signal crosses the zero line. Not sure what the units are here.\n",
    "\n",
    "harmony - Not sure how this was calculated. I'm guessing this is the inverse of dissonance. This is probably higher as a result of spectral peaks being in line with each other. I'll interpret this as the farther away from zero, the more dissonant or noisy a song is.\n",
    "\n",
    "perceptr - difficult to know what this means in context. Could be short for perceptron. Could be taking each value and making them either -1 or 1 depending on what side they're on and taking the overall mean\n",
    "\n",
    "tempo - perceived speed of the song. BPM or toe taps per minute.\n",
    "\n",
    "mfcc***x*** - Mel Frequency Cepstral Coefficients. Essentially a dimensionality reduction of the frequency spectrum over time. Uses the Mel Frequency to transform the frequency into a scale that more accurately represents the way humans hear sound. Used commonly for speech recognition and deconvultion (echo/noise reduction). The higher the ***x*** the higher up in the frequency spectrum it is transforming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"import warnings\\n\\nimport pandas as pd\\nimport numpy as np\\nimport pickle\\n\\nimport statsmodels.api as sm\\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\\n\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n\\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\\nfrom sklearn.metrics import (\\n    classification_report,\\n    confusion_matrix,\\n)\\n\\nfrom sklearn.pipeline import Pipeline\\nfrom sklearn.compose import ColumnTransformer\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.neighbors import KNeighborsClassifier\\n\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.svm import SVC\";\n",
       "                var nbb_formatted_code = \"import warnings\\n\\nimport pandas as pd\\nimport numpy as np\\nimport pickle\\n\\nimport statsmodels.api as sm\\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\\n\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n\\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\\nfrom sklearn.metrics import (\\n    classification_report,\\n    confusion_matrix,\\n)\\n\\nfrom sklearn.pipeline import Pipeline\\nfrom sklearn.compose import ColumnTransformer\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.neighbors import KNeighborsClassifier\\n\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.svm import SVC\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    ")\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"def print_vif(x):\\n    \\\"\\\"\\\"Utility for checking multicollinearity assumption\\n    \\n    :param x: input features to check using VIF. This is assumed to be a pandas.DataFrame\\n    :return: nothing is returned the VIFs are printed as a pandas series\\n    \\\"\\\"\\\"\\n    # Silence numpy FutureWarning about .ptp\\n    with warnings.catch_warnings():\\n        warnings.simplefilter(\\\"ignore\\\")\\n        x = sm.add_constant(x)\\n\\n    vifs = []\\n    for i in range(x.shape[1]):\\n        vif = variance_inflation_factor(x.values, i)\\n        vifs.append(vif)\\n\\n    print(\\\"VIF results\\\\n-------------------------------\\\")\\n    print(pd.Series(vifs, index=x.columns))\\n    print(\\\"-------------------------------\\\\n\\\")\";\n",
       "                var nbb_formatted_code = \"def print_vif(x):\\n    \\\"\\\"\\\"Utility for checking multicollinearity assumption\\n    \\n    :param x: input features to check using VIF. This is assumed to be a pandas.DataFrame\\n    :return: nothing is returned the VIFs are printed as a pandas series\\n    \\\"\\\"\\\"\\n    # Silence numpy FutureWarning about .ptp\\n    with warnings.catch_warnings():\\n        warnings.simplefilter(\\\"ignore\\\")\\n        x = sm.add_constant(x)\\n\\n    vifs = []\\n    for i in range(x.shape[1]):\\n        vif = variance_inflation_factor(x.values, i)\\n        vifs.append(vif)\\n\\n    print(\\\"VIF results\\\\n-------------------------------\\\")\\n    print(pd.Series(vifs, index=x.columns))\\n    print(\\\"-------------------------------\\\\n\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def print_vif(x):\n",
    "    \"\"\"Utility for checking multicollinearity assumption\n",
    "    \n",
    "    :param x: input features to check using VIF. This is assumed to be a pandas.DataFrame\n",
    "    :return: nothing is returned the VIFs are printed as a pandas series\n",
    "    \"\"\"\n",
    "    # Silence numpy FutureWarning about .ptp\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        x = sm.add_constant(x)\n",
    "\n",
    "    vifs = []\n",
    "    for i in range(x.shape[1]):\n",
    "        vif = variance_inflation_factor(x.values, i)\n",
    "        vifs.append(vif)\n",
    "\n",
    "    print(\"VIF results\\n-------------------------------\")\n",
    "    print(pd.Series(vifs, index=x.columns))\n",
    "    print(\"-------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"# To use all\\n# df_long = pd.read_csv(\\\"../data/features_30_sec.csv\\\")\\n# df_short = pd.read_csv(\\\"../data/features_3_sec.csv\\\")\\n# df = pd.concat((df_long, df_short))\\n\\n# To use just one\\n# df = pd.read_csv(\\\"../data/features_30_sec.csv\\\")\\ndf = pd.read_csv(\\\"../data/features_3_sec.csv\\\")\\n\\ndf[\\\"genre\\\"] = df[\\\"filename\\\"].str.split(\\\".\\\").str[0]\\n\\n# \\\"blues.00000.0.wav\\\" -> \\\"blues.00000\\\"\\n# and\\n# \\\"blues.00000.wav\\\" -> \\\"blues.00000\\\"\\n# logic: split on period, take first 2 elements, and but back together\\ndf[\\\"songname\\\"] = df[\\\"filename\\\"].str.split(\\\".\\\").str[:2].str.join(\\\".\\\")\";\n",
       "                var nbb_formatted_code = \"# To use all\\n# df_long = pd.read_csv(\\\"../data/features_30_sec.csv\\\")\\n# df_short = pd.read_csv(\\\"../data/features_3_sec.csv\\\")\\n# df = pd.concat((df_long, df_short))\\n\\n# To use just one\\n# df = pd.read_csv(\\\"../data/features_30_sec.csv\\\")\\ndf = pd.read_csv(\\\"../data/features_3_sec.csv\\\")\\n\\ndf[\\\"genre\\\"] = df[\\\"filename\\\"].str.split(\\\".\\\").str[0]\\n\\n# \\\"blues.00000.0.wav\\\" -> \\\"blues.00000\\\"\\n# and\\n# \\\"blues.00000.wav\\\" -> \\\"blues.00000\\\"\\n# logic: split on period, take first 2 elements, and but back together\\ndf[\\\"songname\\\"] = df[\\\"filename\\\"].str.split(\\\".\\\").str[:2].str.join(\\\".\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To use all\n",
    "# df_long = pd.read_csv(\"../data/features_30_sec.csv\")\n",
    "# df_short = pd.read_csv(\"../data/features_3_sec.csv\")\n",
    "# df = pd.concat((df_long, df_short))\n",
    "\n",
    "# To use just one\n",
    "# df = pd.read_csv(\"../data/features_30_sec.csv\")\n",
    "df = pd.read_csv(\"../data/features_3_sec.csv\")\n",
    "\n",
    "df[\"genre\"] = df[\"filename\"].str.split(\".\").str[0]\n",
    "\n",
    "# \"blues.00000.0.wav\" -> \"blues.00000\"\n",
    "# and\n",
    "# \"blues.00000.wav\" -> \"blues.00000\"\n",
    "# logic: split on period, take first 2 elements, and but back together\n",
    "df[\"songname\"] = df[\"filename\"].str.split(\".\").str[:2].str.join(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"# generated by tuning vif and then checking model coefficients while tuning\\nkeep_cols = [\\n    \\\"chroma_stft_mean\\\",\\n    \\\"chroma_stft_var\\\",\\n    \\\"rms_var\\\",\\n    \\\"zero_crossing_rate_mean\\\",\\n    \\\"zero_crossing_rate_var\\\",\\n    \\\"harmony_mean\\\",\\n    \\\"harmony_var\\\",\\n    \\\"perceptr_mean\\\",\\n    \\\"tempo\\\",\\n    \\\"mfcc1_mean\\\",\\n    \\\"mfcc2_mean\\\",\\n    \\\"mfcc2_var\\\",\\n    \\\"mfcc3_mean\\\",\\n    \\\"mfcc3_var\\\",\\n    \\\"mfcc4_mean\\\",\\n    \\\"mfcc4_var\\\",\\n    \\\"mfcc5_var\\\",\\n    \\\"mfcc6_mean\\\",\\n    \\\"mfcc6_var\\\",\\n    \\\"mfcc7_mean\\\",\\n    \\\"mfcc8_mean\\\",\\n    \\\"mfcc8_var\\\",\\n    \\\"mfcc9_mean\\\",\\n    \\\"mfcc9_var\\\",\\n    \\\"mfcc10_var\\\",\\n    \\\"mfcc12_mean\\\",\\n    \\\"mfcc12_var\\\",\\n    \\\"mfcc13_mean\\\",\\n    \\\"mfcc15_mean\\\",\\n    \\\"mfcc15_var\\\",\\n    \\\"mfcc16_mean\\\",\\n    \\\"mfcc16_var\\\",\\n    \\\"mfcc17_mean\\\",\\n    \\\"mfcc18_mean\\\",\\n    \\\"mfcc19_mean\\\",\\n    \\\"mfcc19_var\\\",\\n]\";\n",
       "                var nbb_formatted_code = \"# generated by tuning vif and then checking model coefficients while tuning\\nkeep_cols = [\\n    \\\"chroma_stft_mean\\\",\\n    \\\"chroma_stft_var\\\",\\n    \\\"rms_var\\\",\\n    \\\"zero_crossing_rate_mean\\\",\\n    \\\"zero_crossing_rate_var\\\",\\n    \\\"harmony_mean\\\",\\n    \\\"harmony_var\\\",\\n    \\\"perceptr_mean\\\",\\n    \\\"tempo\\\",\\n    \\\"mfcc1_mean\\\",\\n    \\\"mfcc2_mean\\\",\\n    \\\"mfcc2_var\\\",\\n    \\\"mfcc3_mean\\\",\\n    \\\"mfcc3_var\\\",\\n    \\\"mfcc4_mean\\\",\\n    \\\"mfcc4_var\\\",\\n    \\\"mfcc5_var\\\",\\n    \\\"mfcc6_mean\\\",\\n    \\\"mfcc6_var\\\",\\n    \\\"mfcc7_mean\\\",\\n    \\\"mfcc8_mean\\\",\\n    \\\"mfcc8_var\\\",\\n    \\\"mfcc9_mean\\\",\\n    \\\"mfcc9_var\\\",\\n    \\\"mfcc10_var\\\",\\n    \\\"mfcc12_mean\\\",\\n    \\\"mfcc12_var\\\",\\n    \\\"mfcc13_mean\\\",\\n    \\\"mfcc15_mean\\\",\\n    \\\"mfcc15_var\\\",\\n    \\\"mfcc16_mean\\\",\\n    \\\"mfcc16_var\\\",\\n    \\\"mfcc17_mean\\\",\\n    \\\"mfcc18_mean\\\",\\n    \\\"mfcc19_mean\\\",\\n    \\\"mfcc19_var\\\",\\n]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generated by tuning vif and then checking model coefficients while tuning\n",
    "keep_cols = [\n",
    "    \"chroma_stft_mean\",\n",
    "    \"chroma_stft_var\",\n",
    "    \"rms_var\",\n",
    "    \"zero_crossing_rate_mean\",\n",
    "    \"zero_crossing_rate_var\",\n",
    "    \"harmony_mean\",\n",
    "    \"harmony_var\",\n",
    "    \"perceptr_mean\",\n",
    "    \"tempo\",\n",
    "    \"mfcc1_mean\",\n",
    "    \"mfcc2_mean\",\n",
    "    \"mfcc2_var\",\n",
    "    \"mfcc3_mean\",\n",
    "    \"mfcc3_var\",\n",
    "    \"mfcc4_mean\",\n",
    "    \"mfcc4_var\",\n",
    "    \"mfcc5_var\",\n",
    "    \"mfcc6_mean\",\n",
    "    \"mfcc6_var\",\n",
    "    \"mfcc7_mean\",\n",
    "    \"mfcc8_mean\",\n",
    "    \"mfcc8_var\",\n",
    "    \"mfcc9_mean\",\n",
    "    \"mfcc9_var\",\n",
    "    \"mfcc10_var\",\n",
    "    \"mfcc12_mean\",\n",
    "    \"mfcc12_var\",\n",
    "    \"mfcc13_mean\",\n",
    "    \"mfcc15_mean\",\n",
    "    \"mfcc15_var\",\n",
    "    \"mfcc16_mean\",\n",
    "    \"mfcc16_var\",\n",
    "    \"mfcc17_mean\",\n",
    "    \"mfcc18_mean\",\n",
    "    \"mfcc19_mean\",\n",
    "    \"mfcc19_var\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"X = df[keep_cols]\\ny = df[\\\"genre\\\"]\";\n",
       "                var nbb_formatted_code = \"X = df[keep_cols]\\ny = df[\\\"genre\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = df[keep_cols]\n",
    "y = df[\"genre\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"# Log all the variance features because of their distributions\\nX_logged = X.copy()\\nfor c in X_logged:\\n    if c.endswith(\\\"_var\\\"):\\n        X_logged[c] = np.log(X_logged[c])\";\n",
       "                var nbb_formatted_code = \"# Log all the variance features because of their distributions\\nX_logged = X.copy()\\nfor c in X_logged:\\n    if c.endswith(\\\"_var\\\"):\\n        X_logged[c] = np.log(X_logged[c])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Log all the variance features because of their distributions\n",
    "X_logged = X.copy()\n",
    "for c in X_logged:\n",
    "    if c.endswith(\"_var\"):\n",
    "        X_logged[c] = np.log(X_logged[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIF results\n",
      "-------------------------------\n",
      "const                      1687.442676\n",
      "chroma_stft_mean              3.821127\n",
      "chroma_stft_var               2.578163\n",
      "rms_var                       4.034234\n",
      "zero_crossing_rate_mean       5.687919\n",
      "zero_crossing_rate_var        4.774067\n",
      "harmony_mean                  1.478989\n",
      "harmony_var                   5.263573\n",
      "perceptr_mean                 1.575745\n",
      "tempo                         1.009630\n",
      "mfcc1_mean                    8.873844\n",
      "mfcc2_mean                    6.108025\n",
      "mfcc2_var                     2.658020\n",
      "mfcc3_mean                    2.402190\n",
      "mfcc3_var                     2.499945\n",
      "mfcc4_mean                    2.261148\n",
      "mfcc4_var                     2.863863\n",
      "mfcc5_var                     2.733756\n",
      "mfcc6_mean                    3.361297\n",
      "mfcc6_var                     2.972196\n",
      "mfcc7_mean                    2.951355\n",
      "mfcc8_mean                    3.618786\n",
      "mfcc8_var                     2.520901\n",
      "mfcc9_mean                    2.682485\n",
      "mfcc9_var                     2.349428\n",
      "mfcc10_var                    2.178830\n",
      "mfcc12_mean                   2.446376\n",
      "mfcc12_var                    2.049463\n",
      "mfcc13_mean                   2.373653\n",
      "mfcc15_mean                   2.294088\n",
      "mfcc15_var                    2.191025\n",
      "mfcc16_mean                   2.151670\n",
      "mfcc16_var                    2.137520\n",
      "mfcc17_mean                   2.244895\n",
      "mfcc18_mean                   1.999290\n",
      "mfcc19_mean                   1.573327\n",
      "mfcc19_var                    1.861491\n",
      "dtype: float64\n",
      "-------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"# Double check for multicollinearity\\nprint_vif(X_logged)\";\n",
       "                var nbb_formatted_code = \"# Double check for multicollinearity\\nprint_vif(X_logged)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Double check for multicollinearity\n",
    "print_vif(X_logged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes on Multicollinearity\n",
    "\n",
    "I think it's important to point out here that I ended up dropping many of the metrics that look at the entire frequency spectrum for calculation. All the information they hold is distributed over the Mel Frequency Cepstrum Coefficients, making may of them redundant. Much of what's left over isn't exactly raw frequency data. Below is just one small example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIF results\n",
      "-------------------------------\n",
      "const           270.051095\n",
      "mfcc1_mean        2.373079\n",
      "mfcc2_mean        6.901655\n",
      "mfcc3_mean        1.370123\n",
      "rolloff_mean      9.191105\n",
      "dtype: float64\n",
      "-------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"print_vif(df[[\\\"mfcc1_mean\\\", \\\"mfcc2_mean\\\", \\\"mfcc3_mean\\\", \\\"rolloff_mean\\\"]])\";\n",
       "                var nbb_formatted_code = \"print_vif(df[[\\\"mfcc1_mean\\\", \\\"mfcc2_mean\\\", \\\"mfcc3_mean\\\", \\\"rolloff_mean\\\"]])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_vif(df[[\"mfcc1_mean\", \"mfcc2_mean\", \"mfcc3_mean\", \"rolloff_mean\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7990, 36) (7990,)\n",
      "(2000, 36) (2000,)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"# og: \\\"blues.00000.0.wav\\\"\\n# songname: \\\"blues.00000\\\"\\n# genre: \\\"blues\\\"\\nsong_genre = df[[\\\"songname\\\", \\\"genre\\\"]].drop_duplicates()\\n\\n# stratification was done in another notebook.\\n# Some extra steps were taken.\\n# Stratify on the 30 second clips and then project down to the 3 second clips\\n\\ntrain_songs = pickle.load(open(\\\"../data/train_songs.p\\\", \\\"rb\\\"))\\ntest_songs = pickle.load(open(\\\"../data/test_songs.p\\\", \\\"rb\\\"))\\n\\ntrain_idxs = df[df[\\\"songname\\\"].isin(train_songs)].index\\ntest_idxs = df[df[\\\"songname\\\"].isin(test_songs)].index\\n\\nX_train = X_logged.loc[train_idxs, :]\\nX_test = X_logged.loc[test_idxs, :]\\ny_train = y[train_idxs]\\ny_test = y[test_idxs]\\n\\nprint(X_train.shape, y_train.shape)\\nprint(X_test.shape, y_test.shape)\";\n",
       "                var nbb_formatted_code = \"# og: \\\"blues.00000.0.wav\\\"\\n# songname: \\\"blues.00000\\\"\\n# genre: \\\"blues\\\"\\nsong_genre = df[[\\\"songname\\\", \\\"genre\\\"]].drop_duplicates()\\n\\n# stratification was done in another notebook.\\n# Some extra steps were taken.\\n# Stratify on the 30 second clips and then project down to the 3 second clips\\n\\ntrain_songs = pickle.load(open(\\\"../data/train_songs.p\\\", \\\"rb\\\"))\\ntest_songs = pickle.load(open(\\\"../data/test_songs.p\\\", \\\"rb\\\"))\\n\\ntrain_idxs = df[df[\\\"songname\\\"].isin(train_songs)].index\\ntest_idxs = df[df[\\\"songname\\\"].isin(test_songs)].index\\n\\nX_train = X_logged.loc[train_idxs, :]\\nX_test = X_logged.loc[test_idxs, :]\\ny_train = y[train_idxs]\\ny_test = y[test_idxs]\\n\\nprint(X_train.shape, y_train.shape)\\nprint(X_test.shape, y_test.shape)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# og: \"blues.00000.0.wav\"\n",
    "# songname: \"blues.00000\"\n",
    "# genre: \"blues\"\n",
    "song_genre = df[[\"songname\", \"genre\"]].drop_duplicates()\n",
    "\n",
    "# stratification was done in another notebook.\n",
    "# Some extra steps were taken.\n",
    "# Stratify on the 30 second clips and then project down to the 3 second clips\n",
    "\n",
    "train_songs = pickle.load(open(\"../data/train_songs.p\", \"rb\"))\n",
    "test_songs = pickle.load(open(\"../data/test_songs.p\", \"rb\"))\n",
    "\n",
    "train_idxs = df[df[\"songname\"].isin(train_songs)].index\n",
    "test_idxs = df[df[\"songname\"].isin(test_songs)].index\n",
    "\n",
    "X_train = X_logged.loc[train_idxs, :]\n",
    "X_test = X_logged.loc[test_idxs, :]\n",
    "y_train = y[train_idxs]\n",
    "y_test = y[test_idxs]\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"# Prove no overlap of songs between train/test\\nset(train_songs).intersection(set(test_songs))\";\n",
       "                var nbb_formatted_code = \"# Prove no overlap of songs between train/test\\nset(train_songs).intersection(set(test_songs))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prove no overlap of songs between train/test\n",
    "set(train_songs).intersection(set(test_songs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7321652065081352\n",
      "0.628\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"num_cols = list(X.columns)\\n\\npreprocessing = ColumnTransformer(\\n    [\\n        # Scale numeric columns (not needed for all models but can't hurt)\\n        (\\\"scaler\\\", StandardScaler(), num_cols)\\n    ],\\n    remainder=\\\"passthrough\\\",\\n)\\n\\n\\npipeline_knn = Pipeline(\\n    [\\n        (\\\"preprocessing\\\", preprocessing),\\n        #         (\\\"pca\\\", PCA()),\\n        # Choose your model and put it here\\n        (\\\"knn\\\", KNeighborsClassifier(weights=\\\"uniform\\\", n_neighbors=100)),\\n    ]\\n)\\n\\n\\npipeline_knn.fit(X_train, y=y_train)\\n\\n\\nprint(pipeline_knn.score(X_train, y_train))\\nprint(pipeline_knn.score(X_test, y_test))\";\n",
       "                var nbb_formatted_code = \"num_cols = list(X.columns)\\n\\npreprocessing = ColumnTransformer(\\n    [\\n        # Scale numeric columns (not needed for all models but can't hurt)\\n        (\\\"scaler\\\", StandardScaler(), num_cols)\\n    ],\\n    remainder=\\\"passthrough\\\",\\n)\\n\\n\\npipeline_knn = Pipeline(\\n    [\\n        (\\\"preprocessing\\\", preprocessing),\\n        #         (\\\"pca\\\", PCA()),\\n        # Choose your model and put it here\\n        (\\\"knn\\\", KNeighborsClassifier(weights=\\\"uniform\\\", n_neighbors=100)),\\n    ]\\n)\\n\\n\\npipeline_knn.fit(X_train, y=y_train)\\n\\n\\nprint(pipeline_knn.score(X_train, y_train))\\nprint(pipeline_knn.score(X_test, y_test))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_cols = list(X.columns)\n",
    "\n",
    "preprocessing = ColumnTransformer(\n",
    "    [\n",
    "        # Scale numeric columns (not needed for all models but can't hurt)\n",
    "        (\"scaler\", StandardScaler(), num_cols)\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    ")\n",
    "\n",
    "\n",
    "pipeline_knn = Pipeline(\n",
    "    [\n",
    "        (\"preprocessing\", preprocessing),\n",
    "        #         (\"pca\", PCA()),\n",
    "        # Choose your model and put it here\n",
    "        (\"knn\", KNeighborsClassifier(weights=\"uniform\", n_neighbors=100)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "pipeline_knn.fit(X_train, y=y_train)\n",
    "\n",
    "\n",
    "print(pipeline_knn.score(X_train, y_train))\n",
    "print(pipeline_knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Analysis:\n",
    "\n",
    "Due to the nature of the data, it is far too easy for this model to cheat given the fact that for every single observation, there will be at least 9 other entries that will be similar in all features. Model performance on test data can't improve without allowing an extremely high level of overfitting. Weighting based on distance makes this even worse. \n",
    "\n",
    "This problem extends to any type of model that uses decision trees. Both Gradient Boosting and Random Forest Classification were tested with very similar results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: SVC rbf kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9987484355444305\n",
      "0.7165\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"num_cols = list(X.columns)\\n\\npreprocessing = ColumnTransformer(\\n    [\\n        # Scale numeric columns (not needed for all models but can't hurt)\\n        (\\\"scaler\\\", StandardScaler(), num_cols)\\n    ],\\n    remainder=\\\"passthrough\\\",\\n)\\n\\n\\npipeline_svc = Pipeline(\\n    [\\n        (\\\"preprocessing\\\", preprocessing),\\n        #         (\\\"pca\\\", PCA()),\\n        # Choose your model and put it here\\n        (\\\"svc\\\", SVC(kernel=\\\"rbf\\\", C=10)),\\n    ]\\n)\\n\\npipeline_svc.fit(X_train, y_train)\\n\\nprint(pipeline_svc.score(X_train, y_train))\\nprint(pipeline_svc.score(X_test, y_test))\";\n",
       "                var nbb_formatted_code = \"num_cols = list(X.columns)\\n\\npreprocessing = ColumnTransformer(\\n    [\\n        # Scale numeric columns (not needed for all models but can't hurt)\\n        (\\\"scaler\\\", StandardScaler(), num_cols)\\n    ],\\n    remainder=\\\"passthrough\\\",\\n)\\n\\n\\npipeline_svc = Pipeline(\\n    [\\n        (\\\"preprocessing\\\", preprocessing),\\n        #         (\\\"pca\\\", PCA()),\\n        # Choose your model and put it here\\n        (\\\"svc\\\", SVC(kernel=\\\"rbf\\\", C=10)),\\n    ]\\n)\\n\\npipeline_svc.fit(X_train, y_train)\\n\\nprint(pipeline_svc.score(X_train, y_train))\\nprint(pipeline_svc.score(X_test, y_test))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_cols = list(X.columns)\n",
    "\n",
    "preprocessing = ColumnTransformer(\n",
    "    [\n",
    "        # Scale numeric columns (not needed for all models but can't hurt)\n",
    "        (\"scaler\", StandardScaler(), num_cols)\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    ")\n",
    "\n",
    "\n",
    "pipeline_svc = Pipeline(\n",
    "    [\n",
    "        (\"preprocessing\", preprocessing),\n",
    "        #         (\"pca\", PCA()),\n",
    "        # Choose your model and put it here\n",
    "        (\"svc\", SVC(kernel=\"rbf\", C=10)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline_svc.fit(X_train, y_train)\n",
    "\n",
    "print(pipeline_svc.score(X_train, y_train))\n",
    "print(pipeline_svc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC rbf Analysis:\n",
    "\n",
    "Same as before, impossible to achieve a higher testing accuracy than other models without allowing overfitting. Also, fewer parameters to even try and address the overfitting. Linear SVM somewhat addresses this, but at that point I think it's more pertinent to use Logistic Regression both to reduce model complexity and increase explanatory power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model: ElasticNet Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7058823529411765\n",
      "0.65\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"num_cols = list(X.columns)\\n\\npreprocessing = ColumnTransformer(\\n    [\\n        # Scale numeric columns (not needed for all models but can't hurt)\\n        (\\\"scaler\\\", StandardScaler(), num_cols)\\n    ],\\n    remainder=\\\"passthrough\\\",\\n)\\n\\n\\npipeline = Pipeline(\\n    [\\n        (\\\"preprocessing\\\", preprocessing),\\n        #         (\\\"pca\\\", PCA()),\\n        # Choose your model and put it here\\n        (\\n            \\\"log\\\",\\n            LogisticRegression(\\n                max_iter=800, penalty=\\\"elasticnet\\\", solver=\\\"saga\\\", C=0.1, l1_ratio=0.5\\n            ),\\n        ),\\n    ]\\n)\\n\\npipeline.fit(X_train, y_train)\\n\\nprint(pipeline.score(X_train, y_train))\\nprint(pipeline.score(X_test, y_test))\";\n",
       "                var nbb_formatted_code = \"num_cols = list(X.columns)\\n\\npreprocessing = ColumnTransformer(\\n    [\\n        # Scale numeric columns (not needed for all models but can't hurt)\\n        (\\\"scaler\\\", StandardScaler(), num_cols)\\n    ],\\n    remainder=\\\"passthrough\\\",\\n)\\n\\n\\npipeline = Pipeline(\\n    [\\n        (\\\"preprocessing\\\", preprocessing),\\n        #         (\\\"pca\\\", PCA()),\\n        # Choose your model and put it here\\n        (\\n            \\\"log\\\",\\n            LogisticRegression(\\n                max_iter=800, penalty=\\\"elasticnet\\\", solver=\\\"saga\\\", C=0.1, l1_ratio=0.5\\n            ),\\n        ),\\n    ]\\n)\\n\\npipeline.fit(X_train, y_train)\\n\\nprint(pipeline.score(X_train, y_train))\\nprint(pipeline.score(X_test, y_test))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_cols = list(X.columns)\n",
    "\n",
    "preprocessing = ColumnTransformer(\n",
    "    [\n",
    "        # Scale numeric columns (not needed for all models but can't hurt)\n",
    "        (\"scaler\", StandardScaler(), num_cols)\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    ")\n",
    "\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"preprocessing\", preprocessing),\n",
    "        #         (\"pca\", PCA()),\n",
    "        # Choose your model and put it here\n",
    "        (\n",
    "            \"log\",\n",
    "            LogisticRegression(\n",
    "                max_iter=800, penalty=\"elasticnet\", solver=\"saga\", C=0.1, l1_ratio=0.5\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "print(pipeline.score(X_train, y_train))\n",
    "print(pipeline.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ElasticNet Classification\n",
    "\n",
    "The eventual hyper parameters used were tested using a giant 5 fold Grid Search of 180 different combinations using precision as the scoring metric. Having both LASSO and Ridge available was helpful, especially when deciding which features to eventually throw out.\n",
    "\n",
    "The scores are not great, admittedly, but when we use the model on the subsections and then vote on the outcome of the original, there is significant improvement. More on that later. I'd like to point out something fairly interesting in the model coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat</th>\n",
       "      <th>coef</th>\n",
       "      <th>abs_coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mfcc1_mean</td>\n",
       "      <td>-1.441049</td>\n",
       "      <td>1.441049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mfcc2_mean</td>\n",
       "      <td>1.137417</td>\n",
       "      <td>1.137417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rms_var</td>\n",
       "      <td>1.039603</td>\n",
       "      <td>1.039603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>harmony_var</td>\n",
       "      <td>1.028323</td>\n",
       "      <td>1.028323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mfcc4_mean</td>\n",
       "      <td>0.913629</td>\n",
       "      <td>0.913629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zero_crossing_rate_mean</td>\n",
       "      <td>0.832223</td>\n",
       "      <td>0.832223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mfcc6_mean</td>\n",
       "      <td>0.827441</td>\n",
       "      <td>0.827441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mfcc2_var</td>\n",
       "      <td>-0.635519</td>\n",
       "      <td>0.635519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mfcc3_mean</td>\n",
       "      <td>0.508702</td>\n",
       "      <td>0.508702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>mfcc7_mean</td>\n",
       "      <td>-0.503557</td>\n",
       "      <td>0.503557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mfcc5_var</td>\n",
       "      <td>0.475954</td>\n",
       "      <td>0.475954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>mfcc18_mean</td>\n",
       "      <td>-0.436142</td>\n",
       "      <td>0.436142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>mfcc8_mean</td>\n",
       "      <td>0.417508</td>\n",
       "      <td>0.417508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>mfcc12_mean</td>\n",
       "      <td>-0.395273</td>\n",
       "      <td>0.395273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chroma_stft_var</td>\n",
       "      <td>0.324605</td>\n",
       "      <td>0.324605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       feat      coef  abs_coef\n",
       "9                mfcc1_mean -1.441049  1.441049\n",
       "10               mfcc2_mean  1.137417  1.137417\n",
       "2                   rms_var  1.039603  1.039603\n",
       "6               harmony_var  1.028323  1.028323\n",
       "14               mfcc4_mean  0.913629  0.913629\n",
       "3   zero_crossing_rate_mean  0.832223  0.832223\n",
       "17               mfcc6_mean  0.827441  0.827441\n",
       "11                mfcc2_var -0.635519  0.635519\n",
       "12               mfcc3_mean  0.508702  0.508702\n",
       "19               mfcc7_mean -0.503557  0.503557\n",
       "16                mfcc5_var  0.475954  0.475954\n",
       "33              mfcc18_mean -0.436142  0.436142\n",
       "20               mfcc8_mean  0.417508  0.417508\n",
       "25              mfcc12_mean -0.395273  0.395273\n",
       "1           chroma_stft_var  0.324605  0.324605"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"coef_df = pd.DataFrame(\\n    {\\\"feat\\\": X_train.columns, \\\"coef\\\": pipeline.named_steps[\\\"log\\\"].coef_[0]}\\n)\\ncoef_df[\\\"abs_coef\\\"] = np.abs(coef_df[\\\"coef\\\"])\\ncoef_df.sort_values(\\\"abs_coef\\\", ascending=False)[0:15]\";\n",
       "                var nbb_formatted_code = \"coef_df = pd.DataFrame(\\n    {\\\"feat\\\": X_train.columns, \\\"coef\\\": pipeline.named_steps[\\\"log\\\"].coef_[0]}\\n)\\ncoef_df[\\\"abs_coef\\\"] = np.abs(coef_df[\\\"coef\\\"])\\ncoef_df.sort_values(\\\"abs_coef\\\", ascending=False)[0:15]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coef_df = pd.DataFrame(\n",
    "    {\"feat\": X_train.columns, \"coef\": pipeline.named_steps[\"log\"].coef_[0]}\n",
    ")\n",
    "coef_df[\"abs_coef\"] = np.abs(coef_df[\"coef\"])\n",
    "coef_df.sort_values(\"abs_coef\", ascending=False)[0:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the top 15 of 36 in total I ended up using. Much of this may or may not be meaningless to you (it was to me at first), but I'd like to draw attention to 'mfcc18_mean'. Taking the coefficient transformations into mind, this feature represents an incredibly high end of the frequency spectrum. Many of us probably can't hear that high. That means the model is taking into account 'overtones' of the sound which is mostly expressed in things like distortion and noise. It could be helping to separate genres that typically have distortion, like rock and metal, from genres that generally don't, like classical and jazz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"df[\\\"predictions\\\"] = pipeline.predict(X_logged[keep_cols])\";\n",
       "                var nbb_formatted_code = \"df[\\\"predictions\\\"] = pipeline.predict(X_logged[keep_cols])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"predictions\"] = pipeline.predict(X_logged[keep_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"long = pd.read_csv(\\\"../data/features_30_sec.csv\\\")\";\n",
       "                var nbb_formatted_code = \"long = pd.read_csv(\\\"../data/features_30_sec.csv\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "long = pd.read_csv(\"../data/features_30_sec.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"long[\\\"vote_pred\\\"] = \\\"none\\\"\\n\\nfor i in range(long[\\\"filename\\\"].size):\\n    curr_file = long[\\\"filename\\\"][i]\\n    file_stripped = curr_file.strip(\\\".wav\\\")\\n    sub_selection = df[\\\"filename\\\"].str.contains(file_stripped)\\n    prediction = (\\n        df[sub_selection][\\\"predictions\\\"]\\n        .value_counts()\\n        .sort_values(ascending=False)\\n        .index[0]\\n    )\\n    long[\\\"vote_pred\\\"][i] = prediction\";\n",
       "                var nbb_formatted_code = \"long[\\\"vote_pred\\\"] = \\\"none\\\"\\n\\nfor i in range(long[\\\"filename\\\"].size):\\n    curr_file = long[\\\"filename\\\"][i]\\n    file_stripped = curr_file.strip(\\\".wav\\\")\\n    sub_selection = df[\\\"filename\\\"].str.contains(file_stripped)\\n    prediction = (\\n        df[sub_selection][\\\"predictions\\\"]\\n        .value_counts()\\n        .sort_values(ascending=False)\\n        .index[0]\\n    )\\n    long[\\\"vote_pred\\\"][i] = prediction\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "long[\"vote_pred\"] = \"none\"\n",
    "\n",
    "for i in range(long[\"filename\"].size):\n",
    "    curr_file = long[\"filename\"][i]\n",
    "    file_stripped = curr_file.strip(\".wav\")\n",
    "    sub_selection = df[\"filename\"].str.contains(file_stripped)\n",
    "    prediction = (\n",
    "        df[sub_selection][\"predictions\"]\n",
    "        .value_counts()\n",
    "        .sort_values(ascending=False)\n",
    "        .index[0]\n",
    "    )\n",
    "    long[\"vote_pred\"][i] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz',\n",
       "       'metal', 'pop', 'reggae', 'rock'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"pipeline.classes_\";\n",
       "                var nbb_formatted_code = \"pipeline.classes_\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline.classes_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['filename', 'length', 'chroma_stft_mean', 'chroma_stft_var', 'rms_mean',\n",
       "       'rms_var', 'spectral_centroid_mean', 'spectral_centroid_var',\n",
       "       'spectral_bandwidth_mean', 'spectral_bandwidth_var', 'rolloff_mean',\n",
       "       'rolloff_var', 'zero_crossing_rate_mean', 'zero_crossing_rate_var',\n",
       "       'harmony_mean', 'harmony_var', 'perceptr_mean', 'perceptr_var', 'tempo',\n",
       "       'mfcc1_mean', 'mfcc1_var', 'mfcc2_mean', 'mfcc2_var', 'mfcc3_mean',\n",
       "       'mfcc3_var', 'mfcc4_mean', 'mfcc4_var', 'mfcc5_mean', 'mfcc5_var',\n",
       "       'mfcc6_mean', 'mfcc6_var', 'mfcc7_mean', 'mfcc7_var', 'mfcc8_mean',\n",
       "       'mfcc8_var', 'mfcc9_mean', 'mfcc9_var', 'mfcc10_mean', 'mfcc10_var',\n",
       "       'mfcc11_mean', 'mfcc11_var', 'mfcc12_mean', 'mfcc12_var', 'mfcc13_mean',\n",
       "       'mfcc13_var', 'mfcc14_mean', 'mfcc14_var', 'mfcc15_mean', 'mfcc15_var',\n",
       "       'mfcc16_mean', 'mfcc16_var', 'mfcc17_mean', 'mfcc17_var', 'mfcc18_mean',\n",
       "       'mfcc18_var', 'mfcc19_mean', 'mfcc19_var', 'mfcc20_mean', 'mfcc20_var',\n",
       "       'label', 'vote_pred', 'blues', 'classical', 'country', 'disco',\n",
       "       'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock', 'avg_vote'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"long.columns\";\n",
       "                var nbb_formatted_code = \"long.columns\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "long.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'blues'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2645\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2646\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'blues'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-a0f193dc51d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mavg_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mlong\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msub_selection\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mavg_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msub_selection\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mavg_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mavg_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2798\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2799\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2800\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2801\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2646\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2648\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2650\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'blues'"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"for c in pipeline.classes_:\\n    long[c] = 0.0\\n\\nlong[\\\"avg_vote\\\"] = \\\"none\\\"\\n\\nfor i in range(long[\\\"filename\\\"].size):\\n    curr_file = long[\\\"filename\\\"][i]\\n    file_stripped = curr_file.strip(\\\".wav\\\")\\n    sub_selection = df[\\\"filename\\\"].str.contains(file_stripped)\\n    avg_dict = {}\\n    for c in pipeline.classes_:\\n        long[c][i] = df[sub_selection][c].mean()\\n        avg_dict[c] = df[sub_selection][c].mean()\\n        prediction = max(avg_dict, key=avg_dict.get)\\n    long[\\\"avg_vote\\\"][i] = prediction\";\n",
       "                var nbb_formatted_code = \"for c in pipeline.classes_:\\n    long[c] = 0.0\\n\\nlong[\\\"avg_vote\\\"] = \\\"none\\\"\\n\\nfor i in range(long[\\\"filename\\\"].size):\\n    curr_file = long[\\\"filename\\\"][i]\\n    file_stripped = curr_file.strip(\\\".wav\\\")\\n    sub_selection = df[\\\"filename\\\"].str.contains(file_stripped)\\n    avg_dict = {}\\n    for c in pipeline.classes_:\\n        long[c][i] = df[sub_selection][c].mean()\\n        avg_dict[c] = df[sub_selection][c].mean()\\n        prediction = max(avg_dict, key=avg_dict.get)\\n    long[\\\"avg_vote\\\"][i] = prediction\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for c in pipeline.classes_:\n",
    "    long[c] = 0.0\n",
    "\n",
    "long[\"avg_vote\"] = \"none\"\n",
    "\n",
    "for i in range(long[\"filename\"].size):\n",
    "    curr_file = long[\"filename\"][i]\n",
    "    file_stripped = curr_file.strip(\".wav\")\n",
    "    sub_selection = df[\"filename\"].str.contains(file_stripped)\n",
    "    avg_dict = {}\n",
    "    for c in pipeline.classes_:\n",
    "        long[c][i] = df[sub_selection][c].mean()\n",
    "        avg_dict[c] = df[sub_selection][c].mean()\n",
    "        prediction = max(avg_dict, key=avg_dict.get)\n",
    "    long[\"avg_vote\"][i] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"long[\\\"songname\\\"] = long[\\\"filename\\\"].str.split(\\\".\\\").str[:2].str.join(\\\".\\\")\\n\\ntrain_idxs = long[long[\\\"songname\\\"].isin(train_songs)].index\\ntest_idxs = long[long[\\\"songname\\\"].isin(test_songs)].index\\n\\nlong_train = long.loc[train_idxs, :]\\nlong_test = long.loc[test_idxs, :]\";\n",
       "                var nbb_formatted_code = \"long[\\\"songname\\\"] = long[\\\"filename\\\"].str.split(\\\".\\\").str[:2].str.join(\\\".\\\")\\n\\ntrain_idxs = long[long[\\\"songname\\\"].isin(train_songs)].index\\ntest_idxs = long[long[\\\"songname\\\"].isin(test_songs)].index\\n\\nlong_train = long.loc[train_idxs, :]\\nlong_test = long.loc[test_idxs, :]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "long[\"songname\"] = long[\"filename\"].str.split(\".\").str[:2].str.join(\".\")\n",
    "\n",
    "train_idxs = long[long[\"songname\"].isin(train_songs)].index\n",
    "test_idxs = long[long[\"songname\"].isin(test_songs)].index\n",
    "\n",
    "long_train = long.loc[train_idxs, :]\n",
    "long_test = long.loc[test_idxs, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13  0  0  0  0  3  1  0  2  1]\n",
      " [ 0 20  0  0  0  0  0  0  0  0]\n",
      " [ 2  0 13  0  1  1  1  0  0  2]\n",
      " [ 0  0  1 14  2  0  0  1  0  2]\n",
      " [ 0  0  0  1 10  0  1  4  4  0]\n",
      " [ 0  3  1  0  0 16  0  0  0  0]\n",
      " [ 0  0  0  1  1  0 18  0  0  0]\n",
      " [ 0  0  1  0  0  0  0 18  0  1]\n",
      " [ 0  0  2  1  2  0  1  0 13  1]\n",
      " [ 2  0  1  6  0  2  2  1  1  5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       blues       0.76      0.65      0.70        20\n",
      "   classical       0.87      1.00      0.93        20\n",
      "     country       0.68      0.65      0.67        20\n",
      "       disco       0.61      0.70      0.65        20\n",
      "      hiphop       0.62      0.50      0.56        20\n",
      "        jazz       0.73      0.80      0.76        20\n",
      "       metal       0.75      0.90      0.82        20\n",
      "         pop       0.75      0.90      0.82        20\n",
      "      reggae       0.65      0.65      0.65        20\n",
      "        rock       0.42      0.25      0.31        20\n",
      "\n",
      "    accuracy                           0.70       200\n",
      "   macro avg       0.68      0.70      0.69       200\n",
      "weighted avg       0.68      0.70      0.69       200\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"# original 30 second clips\\nprint(confusion_matrix(long_test[\\\"label\\\"], long_test[\\\"vote_pred\\\"]))\\nprint(classification_report(long_test[\\\"label\\\"], long_test[\\\"vote_pred\\\"]))\";\n",
       "                var nbb_formatted_code = \"# original 30 second clips\\nprint(confusion_matrix(long_test[\\\"label\\\"], long_test[\\\"vote_pred\\\"]))\\nprint(classification_report(long_test[\\\"label\\\"], long_test[\\\"vote_pred\\\"]))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# original 30 second clips\n",
    "print(confusion_matrix(long_test[\"label\"], long_test[\"vote_pred\"]))\n",
    "print(classification_report(long_test[\"label\"], long_test[\"vote_pred\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This the result of the 'voting' I mentioned earlier. We see a significant increase in model performance when aggregating the results. I think this is a good case for the potential of this model and makes it worth pursuing 'denser' data. What happens if we don't take the mean and variance of each measurement but actually use all data available? What happens when we have more than 30 seconds for each song? I think this model proves it might be worth investing time into seeing where it goes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
